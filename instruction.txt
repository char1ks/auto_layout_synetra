Похоже, пайплайн «заворачивает» много **правильных** масок не из‑за сегментации, а на этапе **принятия решения** (scoring). По вашим логам:

* `pos_avg = 0.599`, `neg_avg = 0.614`
* диапазоны: `pos=[0.531, 0.676]`, `neg=[0.534, 0.700]`
* приняты только 2 из 22 масок.

Это значит, что **негативные** примеры в среднем оказываются **ближе к маскам**, чем позитивные. При таких числах текущая логика классификатора закономерно отклоняет большинство кандидатов.

Ниже — что именно происходит в коде, почему это бьёт по качеству и как это исправить.

---

## 1) Что делает код в вашем случае (коротко)

В `scoring.py` (класс **ScoreCalculator**) решение «принять/отклонить» строится так (упрощённо):

```python
# скоры переводятся в [0..1] из косинусных сходств
pos_s  # агрегированный позитивный скор для маски
neg_s  # агрегированный негативный скор (сейчас это МАКСИМУМ по всем негативам)

diff = pos_s - neg_s
ratio_ok = (pos_s / (neg_s + 1e-8)) >= ratio  # по умолчанию ratio=1.05

base_ok = (pos_s >= min_pos_score) and (pos_s > neg_s)   # min_pos_score по умолчанию 0.58
diff_ok = (diff >= decision_threshold) or ratio_ok       # decision_threshold по умолчанию 0.06

accepted_std = base_ok and diff_ok and (neg_s <= neg_cap) and consensus_ok
# при adaptive_mode добавляется ещё блок с порогом adapt_thr = max_pos * adaptive_ratio (по умолчанию 0.95)
```

Ключевые моменты:

* **neg\_s считается как `max` по всем негативам** → достаточно **одного** «похожего» негативного примера, и почти любая маска проваливается.
* У вас **во многих масках `neg_s ≥ pos_s`** (напр., Маска 1: `pos=0.660`, `neg=0.687`, diff=-0.027). Это ломает `base_ok` (требование `pos > neg`).
* Даже там, где `pos > neg`, разница обычно **мала** (0.01–0.03), а у вас стоит `decision_threshold=0.06` и `ratio=1.05`. В итоге срабатывает правило «слишком маленький отрыв» → отклонить.
* Адаптивный режим у вас включился (`adaptive_mode=True`), но с `adaptive_ratio=0.95` порог вышел высоким (`adapt_thr ~ 0.642`), а `adaptive_diff_floor=0.15` слишком жёсткий для ваших реальных диффов (0.01–0.03). Потому он почти не помогает.

Итог: **даже правильные дефекты** отклоняются, потому что **один «злой» негатив** дает высокий `neg_s`, а текущие пороги требуют слишком большого запаса победы над негативом.

---

## 2) Почему так получается именно у вас

1. **Негативная подборка «жестче» позитивной.**
   Судя по средним/максимумам, в `negative` папке есть изображения **очень похожие на фон/текстуры** вокруг ваших дефектов — или даже с самим объектом. Из‑за этого `neg_s` часто получается выше `pos_s`.

2. **Агрегация негативов через MAX** (одно худшее совпадение решает всё).
   Это даёт много ложных отклонений, если среди негативов есть хоть парочка «почти‑положительных» картинок.

3. **Позитивные векторы считаются по целой картинке** (см. `EmbeddingExtractor.build_queries_multiclass`), а маски — по локальному кропу.
   Если дефект маленький, глобальный эмбеддинг позитива «размыт» фоном, и локальная маска оказывается чуть ближе к некоторым негативам (особенно если фон похож).

4. **Пороговая политика слишком консервативна для текущих данных.**
   Параметры `decision_threshold=0.06`, `ratio=1.05`, `adaptive_ratio=0.95`, `adaptive_diff_floor=0.15` требуют большого отрыва, которого в ваших числах нет.

5. **Структура папок:** в логах есть класс `'.ipynb_checkpoints'` (0 примеров).
   Такие скрытые системные папки лучше **игнорировать**, чтобы не засорять мультикласс‑логику.

---

## 3) Что сделать: быстрые настройки без правки кода

Если у вас есть возможность передать параметры в `ScoreCalculator` (они читаются из `params`), попробуйте **мягко** раскрутить фильтр:

```yaml
min_pos_score:         0.56   # было 0.58 — слегка снизить
decision_threshold:    0.02   # было 0.06 — под реальные диффы 0.01–0.03
score_ratio:           1.01   # было 1.05 — разрешаем небольшой перевес
adaptive_ratio:        0.90   # было 0.95 — адаптивный порог станет ниже
adaptive_diff_floor:   0.02   # было 0.15 — начнёт спасать случаи с малым диффом
topk:                  5      # было 3 — устойчивее к шуму в позитивных примерах
consensus_k:           1      # оставьте 1, если у вас нет множества аугментаций
consensus_thr:         0.58   # можно оставить как есть
```

> Это **не уберёт** проблему MAX по негативам, но в ваших числах уже заметно увеличит долю принятых масок, особенно там, где `pos > neg`, но отрыв мал.

---

## 4) Рекомендуемая правка кода (сильно повышает устойчивость)

### 4.1. Сделать агрегатор негативов устойчивым к выбросам

Смените максимальное объединение негативов на «квазимакс» — например **перцентиль** или **mean top‑k**. Это резко снизит влияние одиночного «злого» негатива.

В `scoring.py` замените `_aggregate_negative` так, чтобы можно было выбирать режим через параметры:

```python
def _aggregate_negative(self, sims_neg: np.ndarray) -> np.ndarray:
    if sims_neg.size == 0 or sims_neg.shape[1] == 0:
        return np.zeros((sims_neg.shape[0] if sims_neg.ndim > 0 else 0,), dtype=np.float32)

    # Переводим в [0..1]
    neg01 = np.clip((sims_neg + 1.0) * 0.5, 0.0, 1.0)

    mode = str(self.params.get('neg_agg', 'p95')).lower()  # 'max' | 'topk' | 'p95'
    if mode == 'max':
        neg = neg01.max(axis=1)
    elif mode == 'topk':
        k = int(self.params.get('neg_topk', 3))
        k = max(1, min(k, neg01.shape[1]))
        part = np.partition(neg01, -k, axis=1)[:, -k:]
        neg = part.mean(axis=1)
    else:  # 'p95' по умолчанию
        p = float(self.params.get('neg_percentile', 95.0))
        p = max(50.0, min(p, 100.0))
        neg = np.percentile(neg01, p, axis=1)

    return neg.astype(np.float32)
```

И параметрами включите, например:

```yaml
neg_agg:          "p95"    # или "topk"
neg_percentile:   95.0     # если p95
neg_topk:         3        # если topk
```

> На реальной практике **p90–p95** или **mean top‑3** почти всегда заметно лучше «чистого max».

### 4.2. (Опционально) ослабить «обязательное» условие `pos > neg`

Сейчас в `score_multiclass` есть:

```python
base_ok = (pos_s >= self.min_pos_score) and (pos_s > neg_s)
```

Если вы уже используете `diff_ok`/`ratio_ok`, то жёсткая проверка `pos_s > neg_s` часто лишняя. Можно сделать её управляемой параметром:

```python
require_pos_gt_neg = bool(self.params.get('require_pos_gt_neg', True))
base_ok = (pos_s >= self.min_pos_score) and ( (pos_s > neg_s) if require_pos_gt_neg else True )
```

И тогда в конфиге для «мягкого» режима:

```yaml
require_pos_gt_neg: false
```

> Это полезно, если часть ваших позитивов «по абсолюту» высокие (например, `pos_s >= 0.64`), но проигрывают негативу на **0.01–0.02**: такой кейс будет проходить по `decision_threshold`/`ratio` даже при `pos <= neg` (что сейчас запрещено).

---

## 5) Что проверить в данных (часто это корень проблемы)

1. **Содержимое `negative/`:** там не должно быть кадров с объектом/дефектом, даже частично. Проверьте руками top‑похожие негативы к принятым маскам (сейчас код не печатает их имена — имеет смысл добавить отладочный вывод индексов/путей «самых похожих» негативов).

2. **Позитивы лучше «сфокусировать»:** если дефект маленький, глобальный эмбеддинг всей картинки «размывает» сигнал. Хорошо помогает:

   * обрезать позитивы до ROI (если есть аннотации),
   * либо хотя бы центр‑кроп/информативный кроп вместо целого кадра,
   * увеличить разнообразие позитивов (разные ракурсы/освещение/масштабы).

3. **Игнорировать скрытые служебные папки** в позитивных классах. В `detector._load_positive_by_class` добавьте фильтр:

   ```python
   subdirs = [p for p in Path(dir_path).iterdir() if p.is_dir() and not p.name.startswith('.')]
   ```

   Чтобы не появлялись классы вида `'.ipynb_checkpoints'`.

---

## 6) Если хотите «видеть» сегментации даже когда решение «отклонено»

Сейчас кандидаты добавляются в результат **только если `accepted=True`**. Для диагностики удобно временно сохранять **top‑K** масок по `pos_score` даже при `accepted=False` (отдельным списком/оверлеем). Это быстро правится в `detector.find_present_elements()` — перед `continue` можно добавить «debug‑сохранение» масок, у которых `pos_score >= debug_min_pos`.

Например:

```python
if not dec.get('accepted'):
    if self.params.get('keep_debug_candidates', False) and dec.get('pos_score', 0.0) >= self.params.get('debug_min_pos', 0.58):
        # ... добавить в отдельный список для отрисовки/сохранения как "debug"
    else:
        continue
```

---

## 7) Резюме «почему» и «что делать»

**Почему отклоняются «правильные» дефекты:**
негативы в среднем ближе к маскам, чем позитивы; при этом используется слишком строгая пороговая политика, а агрегация негативов через `max` делает систему сверхчувствительной к единичным «почти‑позитивным» негативам.

**Что сделать прямо сейчас (минимум кода):**

* Понизить `decision_threshold` до `0.02`, `score_ratio` до `1.01`, `adaptive_ratio` до `0.90`, `adaptive_diff_floor` до `0.02`.
* Немного понизить `min_pos_score` до `0.56` и увеличить `topk` до `5`.

**Что сделать для устойчивости (правка кода):**

* Сменить агрегатор негативов с `max` на `p95` или `top‑k mean` (см. патч выше).
* (Опционально) убрать жёсткое требование `pos > neg` через параметр.

**Что проверить в данных:**

* Вычистить `negative/` от кадров с объектом/похожим фоном.
* Сузить позитивы до ROI/информативного кропа.
* Игнорировать скрытые папки.

Если хотите, могу подготовить маленький дифф к `scoring.py`, который добавит параметры `neg_agg / neg_percentile / neg_topk / require_pos_gt_neg` и пример конфигурации — внесёте и сможете «под крутилки» подобрать режим под ваши данные.
