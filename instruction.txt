Окей—у тебя «скоро-константы» (0.983/0.014) из-за того, что **масочные эмбеддинги и POS/NEG-квери оказываются в разных пространствах/или маски игнорятся, и ты сравниваешь фактически один и тот же вектор**. Ниже — точные правки «что, где и на что менять» в твоей ветке `DINOv3` (репо: ([GitHub][1])). Я даю инструкции через «найти → заменить/вставить», чтобы ты мог сделать это быстро без дифф-инструментов.

---

# 0) КАК ПРОВЕРИТЬ, ЧТО У ТЕБЯ ИМЕННО ЭТА ПРОБЛЕМА (1 минута)

**Вставь временно** в `embeddings.py` внутри метода, который возвращает эмбеддинги масок (обычно `_extract_fast()` или твой DINOv3-ветвитель), сразу после их вычисления:

```python
print("DEBUG mask_emb std:", np.std(embs, axis=0)[:8], "||", np.std(embs))
```

Если общий `np.std(embs)` близок к нулю → **все масочные эмбеддинги одинаковые** → см. Правку №2 ниже (маски игнорятся, берётся глобалка).
Если std нормальный, а «скоры» всё равно 0.983/0.014 → см. Правку №3 (квери/косинусы).

Удалишь этот print после фикса.

---

# 1) `main.py` — добавить бэкенд и путь к ckpt (если ещё не сделал)

**Найди** добавление аргумента `--backbone` (рядом со списком `['resnet101','dinov2_s',...]`)
**Добавь** `'dinov3_convnext_base'` в `choices`:

```python
parser.add_argument('--backbone', choices=['resnet101','dinov2_s','dinov2_b','dinov2_l','dinov2_g','dinov3_convnext_base'], ...
```

**Сразу ниже по аргументам добавь:**

```python
parser.add_argument('--dinov3-ckpt', help='Путь к .pth для DINOv3 ConvNeXt-B')
```

**Там, где формируешь `detector_params`**, добавь прокидывание пути:

```python
if hasattr(args, 'dinov3_ckpt') and args.dinov3_ckpt:
    detector_params['dinov3_ckpt'] = args.dinov3_ckpt
```

(Эти три правки гарантируют, что все нижележащие модули знают, что мы работаем в DINOv3-режиме и где брать веса.)

---

# 2) `embeddings.py` — ИСПРАВИТЬ извлечение масочных эмбеддингов (корень одинаковых значений)

## 2.1. Инициализация DINOv3 ConvNeXt-B

**В `__init__` класса EmbeddingExtractor (рядом с полями под DINOv2)** добавь поля для DINOv3:

```python
self._dinov3_model = None
self._dinov3_preprocess = None
self.dinov3_ckpt = getattr(detector, 'dinov3_ckpt', None)
```

(Если поля уже есть — оставь.)

**Добавь метод** `_ensure_dinov3_convnext()` (если его нет ИЛИ замени целиком, если он есть и грузит не то). Найди в файле конец класса и **вставь**:

```python
def _ensure_dinov3_convnext(self):
    if self._dinov3_model is not None: return
    import os, torch, timm
    from torchvision import transforms as T
    from torchvision.transforms import InterpolationMode

    if not self.dinov3_ckpt:
        raise FileNotFoundError("Укажи --dinov3-ckpt путь к .pth")

    # ConvNeXt-B без классификатора -> model(x) даёт pooled features
    self._dinov3_model = timm.create_model('convnext_base', pretrained=False, num_classes=0)
    sd = torch.load(self.dinov3_ckpt, map_location='cpu')
    if isinstance(sd, dict) and 'model' in sd: sd = sd['model']
    self._dinov3_model.load_state_dict(sd, strict=False)
    self._dinov3_model.eval()

    img_size = int(os.getenv('SEARCHDET_FEAT_SHORT_SIDE', '224'))
    self._dinov3_preprocess = T.Compose([
        T.Resize((img_size, img_size), interpolation=InterpolationMode.BICUBIC),
        T.ToTensor(),
        T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
    ])
```

## 2.2. Масочный **pooled-извлекающий** метод (исправляет «все маски одинаковые»)

**Найди** твой текущий метод, который отдаёт эмбеддинги масок при DINOv3 (у тебя он мог называться `_extract_with_dinov3_convnext` или идти внутри `_extract_fast()` под веткой `if self.backbone.startswith('dinov3')`).
**ЗАМЕНИ ЕГО ЦЕЛИКОМ на:**

```python
def _extract_with_dinov3_convnext(self, image_np, mask_arrays):
    import torch, cv2, numpy as np
    from PIL import Image as PILImage

    self._ensure_dinov3_convnext()
    if self._dinov3_model is None: 
        return np.zeros((0, 1024), dtype=np.float32)

    # 1) Один прогон полного изображения -> spatial feature map
    x_full = self._dinov3_preprocess(PILImage.fromarray(image_np)).unsqueeze(0)
    with torch.no_grad():
        feats = self._dinov3_model.forward_features(x_full)
        # feats: [1, C, Hf, Wf] для ConvNeXt; иногда timm вернёт dict -> приведи к тензору
        if isinstance(feats, dict):
            # timm convnext обычно возвращает тензор; на всякий случай:
            feats = feats.get('x', None) or feats.get('features', None)
        if feats.ndim == 3:  # [C,Hf,Wf]
            feats = feats.unsqueeze(0)
        assert feats.ndim == 4, "Ожидали [B,C,Hf,Wf] от forward_features"

    B, C, Hf, Wf = feats.shape
    fmap = feats[0].detach().cpu().float().numpy().transpose(1,2,0)  # (Hf,Wf,C)

    embs = []
    for mask in mask_arrays:
        # 2) Маску ресайзим к размеру фич-карты и усредняем ТОЛЬКО по активным позициям
        m = cv2.resize(mask.astype(np.uint8), (Wf, Hf), interpolation=cv2.INTER_NEAREST).astype(bool)
        if not m.any():
            # пустые/шумные маски — fallback: глобальный pooled этой карты
            v = fmap.reshape(-1, C).mean(axis=0).astype(np.float32)
        else:
            v = fmap[m].mean(axis=0).astype(np.float32)
        # 3) Нормализация L2
        v /= (np.linalg.norm(v) + 1e-8)
        # ConvNeXt-B -> 1024-D
        if v.shape[0] != 1024:
            out = np.zeros(1024, dtype=np.float32)
            out[:min(1024, v.shape[0])] = v[:min(1024, v.shape[0])]
            v = out
        embs.append(v)

    return np.stack(embs, axis=0) if embs else np.zeros((0,1024), dtype=np.float32)
```

> До этой правки у тебя, судя по логам, **брался pooled по всему изображению для КАЖДОЙ маски**, поэтому все масочные эмбеддинги получались **одинаковыми**, а косинус с POS-прототипом — почти константой `0.983`.

## 2.3. Ветка вызова в `_extract_fast`/`get_embeddings_for_masks`

**Найди** место, где выбирается бэкенд при извлечении масок (что-то вида):

```python
if self.backbone.startswith('dinov2'):
    ...
elif self.backbone.startswith('dinov3'):
    ...
else:
    ...
```

**Убедись**, что внутри ветки `dinov3` вызывается именно `_extract_with_dinov3_convnext(image_np, mask_arrays)`.

---

# 3) `embeddings.py` — POS/NEG-квери строить в **том же пространстве DINOv3**

**Найди** метод `build_queries_multiclass(self, pos_by_class, neg_imgs)`.

**Сразу ВНАЧАЛЕ метода вставь ветку и СДЕЛАЙ `return`, чтобы не уходить в DINOv2-ветки:**

```python
if str(self.backbone).startswith('dinov3'):
    self._ensure_dinov3_convnext()
    D = 1024

    # NEGATIVE
    neg_list = []
    for img in (neg_imgs or []):
        v = self._get_dinov3_global(np.array(img))   # см. ниже
        v = v.astype(np.float32); v /= (np.linalg.norm(v)+1e-8)
        neg_list.append(v)
    q_neg = np.stack(neg_list, axis=0) if neg_list else np.zeros((0,D), np.float32)

    # POSITIVE
    class_pos = {}
    for cls, imgs in (pos_by_class or {}).items():
        vecs = []
        for img in (imgs or []):
            v = self._get_dinov3_global(np.array(img))
            v = v.astype(np.float32); v /= (np.linalg.norm(v)+1e-8)
            vecs.append(v)
        Q = np.stack(vecs, axis=0) if vecs else np.zeros((0,D), np.float32)
        class_pos[cls] = Q

    return class_pos, q_neg
```

**Добавь** вспомогательный метод (если нет) **в конец файла**:

```python
def _get_dinov3_global(self, image_np):
    import torch
    from PIL import Image as PILImage
    self._ensure_dinov3_convnext()
    x = self._dinov3_preprocess(PILImage.fromarray(image_np)).unsqueeze(0)
    with torch.no_grad():
        vec = self._dinov3_model(x).squeeze(0).cpu().float().numpy()  # pooled 1024-D
    vec /= (np.linalg.norm(vec) + 1e-8)
    if vec.shape[0] != 1024:
        out = np.zeros(1024, dtype=np.float32)
        out[:min(1024, vec.shape[0])] = vec[:min(1024, vec.shape[0])]
        vec = out
    return vec.astype(np.float32)
```

> Это гарантирует, что **и маски, и POS/NEG** находятся **в одном и том же** пространстве DINOv3 ConvNeXt-B (раньше POS/NEG могли строиться DINOv2-веткой).

---

# 4) `scoring.py` — ЧИСТЫЙ косинус без бродкаста/дублирования

**Найди** `ScoreCalculator.score_multiclass()` (по логу он и пишет «ЭТАП 3…»).

**Перед вычислением сходства добавь жёсткую нормализацию и проверь формы**:

```python
# X: эмбеддинги масок, [N, D]
X = np.asarray(mask_embeddings, dtype=np.float32)
X /= (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)

# class_pos: dict[str] -> [K, D]
protos = []
labels = []
for cls, Q in class_pos.items():
    if Q.size == 0:
        p = np.zeros((X.shape[1],), dtype=np.float32)
    else:
        Q = Q.astype(np.float32)
        Q /= (np.linalg.norm(Q, axis=1, keepdims=True) + 1e-8)
        p = Q.mean(axis=0)
        p /= (np.linalg.norm(p) + 1e-8)
    protos.append(p); labels.append(cls)

P = np.stack(protos, axis=0) if protos else np.zeros((0, X.shape[1]), dtype=np.float32)

# Косинусы [N, C] без бродкаста ошибок
S = X @ P.T  # (матрица косинусных сходств)
# Перевод в словарь скоров по классам (если у тебя так устроено)
```

**Убедись, что ты не делаешь такое (ошибка бродкаста):**

```python
# ПЛОХО:
scores = (X * P).sum(-1)     # если формы не [N,D] и [N,D], это даст константу
# Правильно — @:
scores = X @ P.T
```

**И проверь, что ты не используешь «один и тот же вектор» дважды:**

```python
assert not np.allclose(X, P[:1]), "Mask embeddings совпали с прототипом — где-то присваивание не то"
```

---

# 5) `detector.py` — просто убедись, что путь прокинулся

В `__init__` детектора (или где ты принимаешь `params`) **должно быть**:

```python
self.dinov3_ckpt = self.params.get('dinov3_ckpt', None)
```

(Это нужно для `embeddings.py`, см. п.2.1.)

---

# 6) БЫСТРАЯ ПРОВЕРКА ПОСЛЕ ПРАВОК

Запусти на том же изображении с теми же POS/NEG:

```bash
python main.py detect \
  path/to/img.jpg \
  --positive path/to/pos_by_class \
  --negative path/to/neg_dir \
  --backbone dinov3_convnext_base \
  --dinov3-ckpt models/dinov3_convnext_base_pretrain_lvd1689m-801f2ba9.pth \
  --feat-short-side 384
```

Ожидаемо ты **перестанешь видеть константу 0.983**:

* `pos` станет расползаться, например `0.81…0.95`,
* `neg` — `-0.05…0.25` (диапазон зависит от данных).
  Если всё ещё почти константа — распечатай `np.std(embs)` (шаг 0): если ≈0, значит маски по пути где-то схлопываются (присылай тот кусок — поправлю).

---

## ВЕРДИКТ (почему так было) и как это фиксится

**Почему было «всегда 0.983/0.014»:**

1. **Маски игнорились**: в DINOv3-ветке для каждой маски считался **один и тот же глобальный pooled-вектор изображения**, а не masked pooling по фич-карте. Поэтому все `mask_emb[i]` были почти одинаковы → косинус с POS-прототипом ≈ константа 0.983.
2. **POS/NEG квери** собирались **не в том же пространстве**, что маски (ветка DINOv2/ResNet), либо нормализация/бродкаст давали одинаковый результат.
3. В `score_multiclass` местами встречается умножение с бродкастом вместо матричного произведения.

**Как фиксится (шаги):**

* (Шаг 2) Заставить DINOv3 работать **на spatial feature map** и делать **masked average pooling** по активным пикселям маски (а не global pooled картинки).
* (Шаг 3) Строить POS/NEG-квери **тем же бэкендом (DINOv3 ConvNeXt-B)** и обязательно L2-нормировать.
* (Шаг 4) Считать косинусы **через матричное умножение `X @ P.T`** при совпадающих размерах, без бродкаста.
* (Шаг 6) Проверить дисперсию эмбеддингов масок (`np.std`) — она **не должна** быть ≈0.

Сделай эти правки — и твои скоры перестанут «залипать» на одном значении, начнут адекватно разделять POS и NEG. Если вышлетешь один проблемный кадр + пару POS/NEG-примеров, смогу подогнать масочный pooling (например, **top-k pooling** вместо среднего) под твою задачу.

[1]: https://github.com/char1ks/auto_layout_synetra/tree/DINOv3 "GitHub - char1ks/auto_layout_synetra at DINOv3"
