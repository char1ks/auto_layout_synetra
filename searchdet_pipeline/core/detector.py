

"""
–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π SearchDetDetector –¥–ª—è –º–æ–¥—É–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞.
"""

import argparse
import os
import sys
import cv2
import time
import numpy as np
from pathlib import Path
from PIL import Image
sys.path.append('./searchdet-main')
try:
    from mask_withsearch import initialize_sam as init_searchdet
    SEARCHDET_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è SearchDet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    SEARCHDET_AVAILABLE = False
from .mask_generation import MaskGenerator
from .filtering import MaskFilter  
from .embeddings import EmbeddingExtractor
from .scoring import ScoreCalculator
from .step7_result_saving import ResultSaver
from .sam_predictor import SAMPredictor
from .utils import get_image_size, get_feature_map_size, upsample_feature_map
from .dinov3_encoder import DinoV3Encoder
import torch


class SearchDetDetector:
    def __init__(self, **kwargs):
        if not SEARCHDET_AVAILABLE:
            raise RuntimeError("SearchDet –Ω–µ –Ω–∞–π–¥–µ–Ω")
        self.params = kwargs
        self.args = argparse.Namespace(**kwargs)
        self.sam_encoder = self.params.get('sam_encoder', 'vit_l')
        self.sam_model = self.params.get('sam_model', None)
        self.device = self.params.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
        self.half = self.params.get('half', False)
        self.mask_backend = self.params.get('backend', 'sam-hq')
        self.backbone = self.params.get('backbone', 'dinov2_b')
        self.dinov3_ckpt = self.params.get('dinov3_ckpt', None)
        self.nms_iou = self.params.get('nms_iou', 0.5)
        if not self.backbone.startswith('dinov2'):
            feat_short = str(self.params.get('feat_short_side', 384))
            os.environ['SEARCHDET_FEAT_SHORT_SIDE'] = feat_short
            print(f"üîß –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ SEARCHDET_FEAT_SHORT_SIDE={feat_short}")
        else:
            print(f"üîß DINOv2 –±—ç–∫–µ–Ω–¥: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏")
        print(f"üîß –í—ã–±—Ä–∞–Ω SAM —ç–Ω–∫–æ–¥–µ—Ä: {self.sam_encoder}")
        self.searchdet_resnet, self.searchdet_layer, self.searchdet_transform, self.searchdet_sam = init_searchdet()
        if not self.backbone.startswith('dinov2'):
            import torchvision.transforms as transforms
            feat_short_side = int(os.getenv('SEARCHDET_FEAT_SHORT_SIDE', '384'))
            self.searchdet_transform = transforms.Compose([
                transforms.Resize(feat_short_side),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
        else:
            self.searchdet_transform = None
        self.sam_predictor = SAMPredictor(self.searchdet_sam)
        
        self.dinov3_backbone = getattr(self.args, "dinov3_backbone", None) or getattr(self.args, "backbone", None)
        self.dinov3_ckpt     = getattr(self.args, "dinov3_ckpt", None)
        self.dinov3_device   = "cuda" if (getattr(self.args, "device", "cuda") == "cuda" and torch.cuda.is_available()) else "cpu"
        self.dinov3_half     = bool(getattr(self.args, "half", False))
        self.vit_pooling     = getattr(self.args, "vit_pooling", "cls").lower()
        self.pos_agg_mode    = getattr(self.args, "pos_agg_mode", "max").lower()

        self.dinov3_encoder = DinoV3Encoder(
            backbone=self.dinov3_backbone,
            ckpt=self.dinov3_ckpt,
            device=self.dinov3_device,
            half=self.dinov3_half,
            vit_pooling=self.vit_pooling,
        )

        if self.backbone.startswith('dinov3') and self.dinov3_ckpt:
            print(f"üîß –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B: {self.dinov3_ckpt}")
            self._preload_dinov3()
        
        self.mask_generator = MaskGenerator(self)
        self.mask_filter = MaskFilter(self, self.params)
        self.embedding_extractor = EmbeddingExtractor(self)
        self.score_calculator = ScoreCalculator(self, self.params)
        self.result_saver = ResultSaver()
        print("‚úÖ SearchDetDetector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è –º–æ–¥—É–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    
    def _preload_dinov3(self):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        try:
            import torch
            import timm
            import torchvision.transforms as T
            from torchvision.transforms import InterpolationMode
            
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B –º–æ–¥–µ–ª–∏...")
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å ConvNeXt-B –±–µ–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
            self.dinov3_model = timm.create_model('convnext_base', pretrained=False, num_classes=0)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ DINOv3
            if self.dinov3_ckpt and os.path.exists(self.dinov3_ckpt):
                print(f"üîß –ó–∞–≥—Ä—É–∂–∞–µ–º DINOv3 –≤–µ—Å–∞ –∏–∑: {self.dinov3_ckpt}")
                state_dict = torch.load(self.dinov3_ckpt, map_location='cpu')
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã checkpoint
                if 'state_dict' in state_dict:
                    state_dict = state_dict['state_dict']
                elif 'model' in state_dict:
                    state_dict = state_dict['model']
                self.dinov3_model.load_state_dict(state_dict, strict=False)
            else:
                print(f"‚ö†Ô∏è DINOv3 checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.dinov3_ckpt}, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π ImageNet)
            self.dinov3_preprocess = T.Compose([
                T.Resize(256, interpolation=InterpolationMode.BICUBIC),
                T.CenterCrop(224),
                T.ToTensor(),
                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ eval —Ä–µ–∂–∏–º –∏ –Ω–∞ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            self.dinov3_model.eval()
            if torch.cuda.is_available():
                self.dinov3_model = self.dinov3_model.cuda()
                print("üöÄ DINOv3 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ GPU")
            else:
                print("üíª DINOv3 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
                
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if self.dino_half_precision and torch.cuda.is_available():
                self.dinov3_model = self.dinov3_model.half()
                print("‚ö° DINOv3 –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å")
                
            print("‚úÖ DINOv3 ConvNeXt-B —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ DINOv3: {e}")
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º None —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–µ–Ω–∏–≤—É—é –∑–∞–≥—Ä—É–∑–∫—É
            self.dinov3_model = None
            self.dinov3_preprocess = None
    
    def find_present_elements(self, image_path, positive_dir, negative_dir=None, output_dir="output"):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤."""
        print(f"üîç –ú–æ–¥—É–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {image_path}" + "="*60)
        print("üîÑ –î–ï–¢–ê–õ–¨–ù–ê–Ø –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨ –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ú–û–î–£–õ–¨–ù–û–ì–û PIPELINE:")
        print("=" * 80)
        print("8Ô∏è‚É£ searchdet_pipeline/core/detector.py ‚Üí find_present_elements()")
        timing_info = {}
        t_total = time.time()
        t_loading = time.time()
        img_bgr = cv2.imread(str(image_path))
        if img_bgr is None:
            raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        image_np = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        timing_info['image_loading'] = time.time() - t_loading
        print("9Ô∏è‚É£ –®–∞–≥ 1: _load_example_images() - –∑–∞–≥—Ä—É–∑–∫–∞ positive/negative –ø—Ä–∏–º–µ—Ä–æ–≤")
        t_examples = time.time()   
        pos_by_class = self._load_positive_by_class(positive_dir)
        if len(pos_by_class) == 0:
            print("   ‚ùå –ù–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º.")
            return {"found_elements": [], "masks": []}
        total_pos = sum(len(v) for v in pos_by_class.values())
        neg_imgs = self._load_example_images(negative_dir) if negative_dir else []
        timing_info['examples_loading'] = time.time() - t_examples
        print(f"   üìÅ Positive: {total_pos} –≤ {len(pos_by_class)} –∫–ª–∞—Å—Å–∞—Ö	üìÅ Negative: {len(neg_imgs)}")
        print("üîü –®–∞–≥ 2: MaskGenerator.generate() - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ —á–µ—Ä–µ–∑ SAM/FastSAM")
        t_masks = time.time()
        masks = self.mask_generator.generate(image_np)
        timing_info['mask_generation'] = time.time() - t_masks
        print("1Ô∏è‚É£1Ô∏è‚É£ –®–∞–≥ 3-7: MaskFilter.apply_all_filters() - –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –º–∞—Å–æ–∫")
        t_filtering = time.time()
        masks = self.mask_filter.apply_all_filters(masks, image_np)
        timing_info['mask_filtering'] = time.time() - t_filtering
        if not masks:
            print("   ‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
            return {"found_elements": [], "masks": []}
        print("1Ô∏è‚É£2Ô∏è‚É£ –®–∞–≥ 8: EmbeddingExtractor.extract_mask_embeddings() - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫")
        t_embeddings = time.time()
        mask_vecs, idx_map = self.embedding_extractor.extract_mask_embeddings(image_np, masks)
        if mask_vecs.shape[0] == 0:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫.")
            return {"found_elements": [], "masks": []}
        print(f"   üìä –ú–∞—Å–æ–∫ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏: {mask_vecs.shape[0]}")
        print("1Ô∏è‚É£3Ô∏è‚É£ –®–∞–≥ 9: EmbeddingExtractor.build_queries_multiclass() - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º")
        class_pos, q_neg = self.embedding_extractor.build_queries_multiclass(pos_by_class, neg_imgs, pos_as_query_masks=False)
        timing_info['embedding_extraction'] = time.time() - t_embeddings

        online_negatives = None
        # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤—ã
        if q_neg is None or q_neg.shape[0] == 0:
            print("   ‚ö†Ô∏è –ù–µ—Ç —è–≤–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤—ã...")
            
            # 1. –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –æ–¥–∏–Ω —Ç–µ–Ω–∑–æ—Ä
            pos_queries_tensors = [torch.from_numpy(v) for v in class_pos.values() if v.shape[0] > 0]

            if not pos_queries_tensors:
                print("   ‚ùå –ù–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è positive-–∫–ª–∞—Å—Å–æ–≤, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤—ã.")
            else:
                all_pos_queries = torch.cat(pos_queries_tensors, dim=0)

                if all_pos_queries.shape[0] > 0 and mask_vecs.shape[0] > 0:
                    # 2. –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –º–∞—Å–∫–∞–º–∏ –∏ –≤—Å–µ–º–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    mask_vecs_torch = torch.from_numpy(mask_vecs)
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º torch –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏
                    sim_matrix = torch.nn.functional.cosine_similarity(mask_vecs_torch.unsqueeze(1), all_pos_queries.unsqueeze(0), dim=2)

                    # 3. –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Å–∫–æ—Ä –¥–ª—è –∫–∞–∂–¥–æ–π –º–∞—Å–∫–∏
                    best_pos_scores, _ = torch.max(sim_matrix, dim=1)
                    
                    # 4. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤–æ–≤ (–Ω–∏–∂–Ω–∏–µ 40%)
                    num_online_negatives = int(mask_vecs.shape[0] * 0.4)
                    
                    if num_online_negatives > 0:
                        # 5. –ù–∞–π—Ç–∏ –∏–Ω–¥–µ–∫—Å—ã –º–∞—Å–æ–∫ —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º–∏ —Å–∫–æ—Ä–∞–º–∏
                        k = min(num_online_negatives, len(best_pos_scores))
                        if k > 0:
                            _, bottom_indices = torch.topk(best_pos_scores, k=k, largest=False)
                            
                            # 6. –°–æ–±—Ä–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤–æ–≤
                            online_negatives = mask_vecs[bottom_indices.numpy()]
                            print(f"   üí° –°–æ–∑–¥–∞–Ω–æ {online_negatives.shape[0]} –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤–æ–≤ –∏–∑ –º–∞—Å–æ–∫ —Å –Ω–∞–∏—Ö—É–¥—à–∏–º–∏ positive-—Å–∫–æ—Ä–∞–º–∏.")

        print("1Ô∏è‚É£4Ô∏è‚É£ –®–∞–≥ 10: ScoreCalculator.score_multiclass() - —Å–∫–æ—Ä–∏–Ω–≥ –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π")
        print("üîç –≠–¢–ê–ü 3: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å positive/negative –ø–æ –∫–ª–∞—Å—Å–∞–º...")
        t_scoring = time.time()
        decisions = self.score_calculator.score_multiclass(
            mask_vecs, 
            class_pos, 
            q_neg,
            online_negatives=online_negatives
        )
        timing_info['scoring_and_decisions'] = time.time() - t_scoring
        t_result = time.time()
        found = []
        result_masks = []
        candidates = []
        H, W = image_np.shape[:2]
        print(f"\nüîç Processing {len(decisions)} decisions...")
        for i, dec in enumerate(decisions):
            print(f"  - Decision {i}: accepted={dec.get('accepted')}, class='{dec.get('class')}', confidence={dec.get('confidence', 0.0):.3f}")
            if not dec.get('accepted'):
                print(f"    -> SKIPPED (not accepted)")
                continue
            original_idx = idx_map[i]
            print(f"    -> ACCEPTED. Original mask index: {original_idx}")
            mask_dict = masks[original_idx].copy()
            confidence = float(np.clip(dec.get('confidence', 0.0), 0.0, 1.0))
            mask_dict['confidence'] = confidence
            mask_dict['class'] = dec.get('class')
            if 'area' not in mask_dict and 'segmentation' in mask_dict:
                mask_dict['area'] = int(np.sum(mask_dict['segmentation']))
            bx = mask_dict.get('bbox', [0,0,0,0])
            if len(bx) == 4 and (bx[2] <= W and bx[3] <= H):
                x1, y1, w, h = bx
                bbox_xyxy = [int(x1), int(y1), int(x1 + w), int(y1 + h)]
            else:
                bbox_xyxy = [int(bx[0]), int(bx[1]), int(bx[2]), int(bx[3])]
            cls_label = dec.get('class')
            try:
                cls_label = str(cls_label) if cls_label is not None else "__unknown__"
            except Exception:
                cls_label = "__unknown__"
            print(f"    -> Appending candidate: class='{cls_label}', confidence={confidence:.3f}")
            candidates.append({
                'mask': mask_dict['segmentation'].astype(bool),
                'bbox_xyxy': bbox_xyxy,
                'confidence': confidence,
                'area': int(mask_dict['area']),
                'class': cls_label,
            })
        from collections import Counter
        print("NMS candidates by class:", Counter([c.get('class') for c in candidates]))
        kept = self._nms(candidates, class_aware=True)
        for e in kept:
            seg = e['mask']
            x1, y1, x2, y2 = e['bbox_xyxy']
            bbox_xywh = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]
            mask_dict = {
                'segmentation': seg,
                'bbox': bbox_xywh,
                'area': int(seg.sum()),
                'confidence': float(e['confidence']),
                'class': e.get('class')
            }
            found.append({
                'mask': mask_dict,
                'confidence': float(e['confidence']),
                'bbox': bbox_xywh,
                'class': e.get('class')
            })
            result_masks.append(mask_dict)
        timing_info['result_formatting'] = time.time() - t_result
        print("1Ô∏è‚É£5Ô∏è‚É£ –®–∞–≥ 11: ResultSaver.save_all_results() - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤")
        t_saving = time.time()
        image_name = Path(image_path).name
        saved_files = self.result_saver.save_all_results(
            image_np, 
            result_masks, 
            output_dir, 
            image_name,
            pipeline_config={"backend": self.mask_backend}
        )
        timing_info['result_saving'] = time.time() - t_saving
        total_time = time.time() - t_total
        timing_info['total_time'] = total_time
        print(f"üéØ –ü—Ä–∏–Ω—è—Ç–æ –º–∞—Å–æ–∫: {len(found)} (–ø–æ—Å–ª–µ –ø—Ä–∞–≤–∏–ª –∏ NMS)")
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
        print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(saved_files)}")
        self._print_timing_statistics(timing_info)
        return {
            "found_elements": found, 
            "masks": result_masks,
            "timing_info": timing_info,
            "output_directory": output_dir,
            "saved_files": saved_files
        }

    def _mask_iou(self, mask_a, mask_b):
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ IoU –¥–ª—è –º–∞—Å–æ–∫."""
        intersection = np.logical_and(mask_a, mask_b).sum()
        union = np.logical_or(mask_a, mask_b).sum()
        return intersection / union if union > 0 else 0.0

    def _nms(self, elements, class_aware=True, class_thresholds=None):
        """–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è NMS —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π."""
        if not elements:
            return []
        
        try:
            import torch
            import torchvision.ops as ops
            use_torch = True
        except ImportError:
            use_torch = False
            
        from collections import defaultdict
        
        def _class_key(v):
            if v is None:
                return "__unknown__"
            try:
                return str(v)
            except Exception:
                return repr(v)
        
        groups = defaultdict(list)
        if class_aware:
            for el in elements:
                groups[_class_key(el.get('class'))].append(el)
        else:
            groups["__all__"] = list(elements)
        
        kept_all = []
        for cls_key, group in groups.items():
            if not group:
                continue
                
            iou_thr = (class_thresholds or {}).get(cls_key, self.nms_iou)
            
            if use_torch and len(group) > 10:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º torch –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø
                kept_cls = self._nms_torch(group, iou_thr)
            else:
                kept_cls = self._nms_numpy(group, iou_thr)
                
            kept_all.extend(kept_cls)
        
        return kept_all
    
    def _nms_torch(self, elements, iou_threshold):
        """NMS —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º torchvision –¥–ª—è bbox + –º–∞—Å–∫–∏."""
        import torch
        import torchvision.ops as ops
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º bbox –∏ scores
        boxes = []
        scores = []
        for el in elements:
            x1, y1, x2, y2 = el['bbox_xyxy']
            boxes.append([x1, y1, x2, y2])
            scores.append(el.get('confidence', 0.0))
        
        boxes_tensor = torch.tensor(boxes, dtype=torch.float32)
        scores_tensor = torch.tensor(scores, dtype=torch.float32)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º bbox NMS
        keep_indices = ops.nms(boxes_tensor, scores_tensor, iou_threshold)
        bbox_kept = [elements[i] for i in keep_indices.tolist()]
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∞—Å–∫–∞–º –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        if len(bbox_kept) <= 1:
            return bbox_kept
            
        final_kept = []
        for i, current in enumerate(bbox_kept):
            should_keep = True
            current_mask = current['mask']
            
            for j in range(i):
                if j < len(final_kept):
                    other_mask = final_kept[j]['mask']
                    if self._mask_iou(current_mask, other_mask) >= iou_threshold:
                        should_keep = False
                        break
            
            if should_keep:
                final_kept.append(current)
                
        return final_kept
    
    def _nms_numpy(self, elements, iou_threshold):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è numpy —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è NMS."""
        if len(elements) <= 1:
            return elements
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence
        sorted_elements = sorted(elements, key=lambda e: float(e.get('confidence', 0.0)), reverse=True)
        
        kept = []
        masks_kept = []
        
        for current in sorted_elements:
            current_mask = current['mask']
            should_keep = True
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IoU —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏ –º–∞—Å–∫–∞–º–∏
            for kept_mask in masks_kept:
                if self._mask_iou(current_mask, kept_mask) >= iou_threshold:
                    should_keep = False
                    break
            
            if should_keep:
                kept.append(current)
                masks_kept.append(current_mask)
                
        return kept

    def _load_example_images(self, dir_path):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        from pathlib import Path
        from PIL import Image

        images = []
        if not dir_path:
            return images
            
        p_dir = Path(dir_path)
        if not p_dir.exists() or not p_dir.is_dir() or p_dir.name.startswith('.'):
            return images

        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
        
        for item in p_dir.iterdir():
            if item.name.startswith('.'):
                continue
            
            if item.is_dir():
                images.extend(self._load_example_images(item))  # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –≤—ã–∑–æ–≤
            elif item.is_file() and item.suffix.lower() in valid_extensions:
                try:
                    img = Image.open(item).convert('RGB')
                    images.append(img)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {item}: {e}")
        return images

    def _load_positive_by_class(self, dir_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—è –∏—Ö –ø–æ –∫–ª–∞—Å—Å–∞–º."""
        from pathlib import Path
        result = {}
        if not dir_path:
            return result
            
        p_dir = Path(dir_path)
        if not p_dir.exists() or not p_dir.is_dir() or p_dir.name.startswith('.'):
            return result

        # –ò—â–µ–º –Ω–µ—Å–∫—Ä—ã—Ç—ã–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        subdirs = [p for p in p_dir.iterdir() if p.is_dir() and not p.name.startswith('.')]
        
        if subdirs:
            # –†–µ–∂–∏–º 1: –ü–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —è–≤–ª—è—é—Ç—Å—è –∫–ª–∞—Å—Å–∞–º–∏
            print(f"   üìÇ –†–µ–∂–∏–º –º—É–ª—å—Ç–∏-–∫–ª–∞—Å—Å–∞: –ø–æ–¥–ø–∞–ø–∫–∏ –≤ '{p_dir.name}' —Å—á–∏—Ç–∞—é—Ç—Å—è –∫–ª–∞—Å—Å–∞–º–∏.")
            for class_dir in subdirs:
                class_name = class_dir.name
                loaded_images = self._load_example_images(class_dir)
                if loaded_images:
                    result[class_name] = loaded_images
                    print(f"     -> –ö–ª–∞—Å—Å '{class_name}': –Ω–∞–π–¥–µ–Ω–æ {len(loaded_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
                else:
                    print(f"     -> –ö–ª–∞—Å—Å '{class_name}': 0 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        else:
            # –†–µ–∂–∏–º 2: –ù–µ—Ç –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –≤—Å—è –ø–∞–ø–∫–∞ - –æ–¥–∏–Ω –∫–ª–∞—Å—Å
            print(f"   üìÇ –†–µ–∂–∏–º –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞: –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ '{p_dir.name}' –±—É–¥—É—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –∫–ª–∞—Å—Å—É '{p_dir.name}'.")
            class_name = p_dir.name
            loaded_images = self._load_example_images(p_dir)
            if loaded_images:
                result[class_name] = loaded_images
                print(f"     -> –ö–ª–∞—Å—Å '{class_name}': –Ω–∞–π–¥–µ–Ω–æ {len(loaded_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
            else:
                print(f"     -> –ö–ª–∞—Å—Å '{class_name}': 0 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")

        return result
    def _print_timing_statistics(self, timing_info):
        print("\n" + "="*60)
        print("‚è±Ô∏è –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–†–ï–ú–ï–ù–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print("="*60)
        total_time = timing_info['total_time']
        stages = [
            ('image_loading', 'üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'),
            ('examples_loading', 'üñºÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤'),
            ('mask_generation', 'üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ (SAM/FastSAM)'),
            ('mask_filtering', 'üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫'),
            ('embedding_extraction', 'üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤'),
            ('scoring_and_decisions', 'üìä –°–∫–æ—Ä–∏–Ω–≥ –∏ —Ä–µ—à–µ–Ω–∏—è'),
            ('result_formatting', 'üìã –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞'),
            ('result_saving', 'üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤')
        ]
        
        for stage_key, stage_name in stages:
            if stage_key in timing_info:
                stage_time = timing_info[stage_key]
                percentage = (stage_time / total_time * 100) if total_time > 0 else 0
                print(f"{stage_name:<40}: {stage_time:>6.3f}—Å ({percentage:>5.1f}%)")
        print("-" * 60)
        print(f"{'üöÄ –û–ë–©–ï–ï –í–†–ï–ú–Ø':<40}: {total_time:>6.3f}—Å (100.0%)")
        print("="*60)
        stage_times = [(name, timing_info.get(key, 0)) for key, name in stages if key in timing_info]
        stage_times.sort(key=lambda x: x[1], reverse=True)
        if len(stage_times) > 1:
            print("\nüêå –°–ê–ú–´–ï –ú–ï–î–õ–ï–ù–ù–´–ï –≠–¢–ê–ü–´:")
            for i, (name, stage_time) in enumerate(stage_times[:3]):
                percentage = (stage_time / total_time * 100) if total_time > 0 else 0
                print(f"   {i+1}. {name}: {stage_time:.3f}—Å ({percentage:.1f}%)")
        if 'mask_generation' in timing_info and timing_info['mask_generation'] > total_time * 0.5:
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
            print("   ‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ –∑–∞–Ω–∏–º–∞–µ—Ç >50% –≤—Ä–µ–º–µ–Ω–∏")
            print("   ‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ FastSAM –≤–º–µ—Å—Ç–æ SAM-HQ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
            print("   ‚Ä¢ –ò–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã SAM (points_per_side, imgsz)")
        if 'embedding_extraction' in timing_info and timing_info['embedding_extraction'] > total_time * 0.3:
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
            print("   ‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–Ω–∏–º–∞–µ—Ç >30% –≤—Ä–µ–º–µ–Ω–∏")
            print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä feature map (SEARCHDET_FEAT_SHORT_SIDE)")
            print("   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è")
        print()