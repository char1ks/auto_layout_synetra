

"""
–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π SearchDetDetector –¥–ª—è –º–æ–¥—É–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞.
"""

import os
import sys
import cv2
import time
import numpy as np
from pathlib import Path
from PIL import Image
sys.path.append('./searchdet-main')
try:
    from mask_withsearch import initialize_models as init_searchdet
    SEARCHDET_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è SearchDet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    SEARCHDET_AVAILABLE = False
from .mask_generation import MaskGenerator
from .filtering import MaskFilter  
from .embeddings import EmbeddingExtractor
from .scoring import ScoreCalculator
from .step7_result_saving import ResultSaver
from .embeddings import ResNet101Embedding, DINOv3Embedding
from .sam_predictor import SAMPredictor
from .utils import get_image_size, get_feature_map_size, upsample_feature_map


class SearchDetDetector:
    def __init__(self, **kwargs):
        if not SEARCHDET_AVAILABLE:
            raise RuntimeError("SearchDet –Ω–µ –Ω–∞–π–¥–µ–Ω")
        self.params = kwargs
        self.sam_encoder = self.params.get('sam_encoder', 'vit_l')
        self.sam_model = self.params.get('sam_model', None)
        self.backbone = self.params.get('backbone', 'dinov2_b')
        self.dinov3_ckpt = self.params.get('dinov3_ckpt', None)
        if not self.backbone.startswith('dinov2'):
            feat_short = str(self.params.get('feat_short_side', 384))
            os.environ['SEARCHDET_FEAT_SHORT_SIDE'] = feat_short
            print(f"üîß –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ SEARCHDET_FEAT_SHORT_SIDE={feat_short}")
        else:
            print(f"üîß DINOv2 –±—ç–∫–µ–Ω–¥: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏")
        print(f"üîß –í—ã–±—Ä–∞–Ω SAM —ç–Ω–∫–æ–¥–µ—Ä: {self.sam_encoder}")
        self.searchdet_resnet, self.searchdet_layer, self.searchdet_transform, self.searchdet_sam = init_searchdet()
        if not self.backbone.startswith('dinov2'):
            import torchvision.transforms as transforms
            feat_short_side = int(os.getenv('SEARCHDET_FEAT_SHORT_SIDE', '384'))
            self.searchdet_transform = transforms.Compose([
                transforms.Resize(feat_short_side),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
        else:
            print(f"üîß DINOv2: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≤ EmbeddingExtractor")  
        self.searchdet_layer = self.params.get('layer', 'layer3')
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–æ–π –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {self.searchdet_layer}")
        self.mask_backend = self.params.get('mask_backend', 'fastsam')
        self.consensus_k = int(self.params.get('consensus_k', 3))
        self.consensus_thr = float(self.params.get('consensus_thr', 0.60))
        self.nms_iou = float(self.params.get('nms_iou', 0.60))
        # üöÄ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.max_embedding_size = self.params.get('max_embedding_size', 1024)
        self.dino_half_precision = self.params.get('dino_half_precision', False)

        # üöÄ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∞—Å–æ–∫
        default_sam_long = min(1800, self.max_embedding_size)
        self.sam_long_side = int(self.params.get('sam_long_side', default_sam_long))
        self.fastsam_imgsz = int(self.params.get('fastsam_imgsz', 1024))
        self.fastsam_conf = float(self.params.get('fastsam_conf', 0.4))
        self.fastsam_iou = float(self.params.get('fastsam_iou', 0.9))
        self.fastsam_retina = bool(self.params.get('fastsam_retina', True))
        self.ban_border_masks = bool(self.params.get('border_ban', True))
        self.border_width = int(self.params.get('border_width', 2))
        # üöÄ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ DINOv3 –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
        if self.backbone.startswith('dinov3') and self.dinov3_ckpt:
            print(f"üîß –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B: {self.dinov3_ckpt}")
            self._preload_dinov3()
        
        self.mask_generator = MaskGenerator(self)
        self.mask_filter = MaskFilter(self, self.params)
        self.embedding_extractor = EmbeddingExtractor(self)
        self.score_calculator = ScoreCalculator(self, self.params)
        self.result_saver = ResultSaver()
        print("‚úÖ SearchDetDetector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è –º–æ–¥—É–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    
    def _preload_dinov3(self):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞."""
        try:
            import torch
            import timm
            import torchvision.transforms as T
            from torchvision.transforms import InterpolationMode
            
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ DINOv3 ConvNeXt-B –º–æ–¥–µ–ª–∏...")
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å ConvNeXt-B –±–µ–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
            self.dinov3_model = timm.create_model('convnext_base', pretrained=False, num_classes=0)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ DINOv3
            if self.dinov3_ckpt and os.path.exists(self.dinov3_ckpt):
                print(f"üîß –ó–∞–≥—Ä—É–∂–∞–µ–º DINOv3 –≤–µ—Å–∞ –∏–∑: {self.dinov3_ckpt}")
                state_dict = torch.load(self.dinov3_ckpt, map_location='cpu')
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã checkpoint
                if 'state_dict' in state_dict:
                    state_dict = state_dict['state_dict']
                elif 'model' in state_dict:
                    state_dict = state_dict['model']
                self.dinov3_model.load_state_dict(state_dict, strict=False)
            else:
                print(f"‚ö†Ô∏è DINOv3 checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.dinov3_ckpt}, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π ImageNet)
            self.dinov3_preprocess = T.Compose([
                T.Resize(256, interpolation=InterpolationMode.BICUBIC),
                T.CenterCrop(224),
                T.ToTensor(),
                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ eval —Ä–µ–∂–∏–º –∏ –Ω–∞ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            self.dinov3_model.eval()
            if torch.cuda.is_available():
                self.dinov3_model = self.dinov3_model.cuda()
                print("üöÄ DINOv3 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ GPU")
            else:
                print("üíª DINOv3 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
                
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if self.dino_half_precision and torch.cuda.is_available():
                self.dinov3_model = self.dinov3_model.half()
                print("‚ö° DINOv3 –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å")
                
            print("‚úÖ DINOv3 ConvNeXt-B —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ DINOv3: {e}")
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º None —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–µ–Ω–∏–≤—É—é –∑–∞–≥—Ä—É–∑–∫—É
            self.dinov3_model = None
            self.dinov3_preprocess = None
    
    def find_present_elements(self, image_path, positive_dir, negative_dir=None, output_dir="output"):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤."""
        print(f"üîç –ú–æ–¥—É–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {image_path}" + "="*60)
        print("üîÑ –î–ï–¢–ê–õ–¨–ù–ê–Ø –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨ –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ú–û–î–£–õ–¨–ù–û–ì–û PIPELINE:")
        print("=" * 80)
        print("8Ô∏è‚É£ searchdet_pipeline/core/detector.py ‚Üí find_present_elements()")
        timing_info = {}
        t_total = time.time()
        t_loading = time.time()
        img_bgr = cv2.imread(str(image_path))
        if img_bgr is None:
            raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        image_np = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        timing_info['image_loading'] = time.time() - t_loading
        print("9Ô∏è‚É£ –®–∞–≥ 1: _load_example_images() - –∑–∞–≥—Ä—É–∑–∫–∞ positive/negative –ø—Ä–∏–º–µ—Ä–æ–≤")
        t_examples = time.time()   
        pos_by_class = self._load_positive_by_class(positive_dir)
        if len(pos_by_class) == 0:
            print("   ‚ùå –ù–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º.")
            return {"found_elements": [], "masks": []}
        total_pos = sum(len(v) for v in pos_by_class.values())
        neg_imgs = self._load_example_images(negative_dir) if negative_dir else []
        timing_info['examples_loading'] = time.time() - t_examples
        print(f"   üìÅ Positive: {total_pos} –≤ {len(pos_by_class)} –∫–ª–∞—Å—Å–∞—Ö	üìÅ Negative: {len(neg_imgs)}")
        print("üîü –®–∞–≥ 2: MaskGenerator.generate() - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ —á–µ—Ä–µ–∑ SAM/FastSAM")
        t_masks = time.time()
        masks = self.mask_generator.generate(image_np)
        timing_info['mask_generation'] = time.time() - t_masks
        print("1Ô∏è‚É£1Ô∏è‚É£ –®–∞–≥ 3-7: MaskFilter.apply_all_filters() - –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –º–∞—Å–æ–∫")
        t_filtering = time.time()
        masks = self.mask_filter.apply_all_filters(masks, image_np)
        timing_info['mask_filtering'] = time.time() - t_filtering
        if not masks:
            print("   ‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
            return {"found_elements": [], "masks": []}
        print("1Ô∏è‚É£2Ô∏è‚É£ –®–∞–≥ 8: EmbeddingExtractor.extract_mask_embeddings() - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫")
        t_embeddings = time.time()
        mask_vecs, idx_map = self.embedding_extractor.extract_mask_embeddings(image_np, masks)
        if mask_vecs.shape[0] == 0:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫.")
            return {"found_elements": [], "masks": []}
        print(f"   üìä –ú–∞—Å–æ–∫ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏: {mask_vecs.shape[0]}")
        print("1Ô∏è‚É£3Ô∏è‚É£ –®–∞–≥ 9: EmbeddingExtractor.build_queries_multiclass() - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º")
        class_pos, q_neg = self.embedding_extractor.build_queries_multiclass(pos_by_class, neg_imgs)
        timing_info['embedding_extraction'] = time.time() - t_embeddings
        print("1Ô∏è‚É£4Ô∏è‚É£ –®–∞–≥ 10: ScoreCalculator.score_multiclass() - —Å–∫–æ—Ä–∏–Ω–≥ –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π")
        print("üîç –≠–¢–ê–ü 3: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å positive/negative –ø–æ –∫–ª–∞—Å—Å–∞–º...")
        t_scoring = time.time()
        decisions = self.score_calculator.score_multiclass(mask_vecs, class_pos, q_neg)
        timing_info['scoring_and_decisions'] = time.time() - t_scoring
        t_result = time.time()
        found = []
        result_masks = []
        candidates = []
        H, W = image_np.shape[:2]
        print(f"\nüîç Processing {len(decisions)} decisions...")
        for i, dec in enumerate(decisions):
            print(f"  - Decision {i}: accepted={dec.get('accepted')}, class='{dec.get('class')}', confidence={dec.get('confidence', 0.0):.3f}")
            if not dec.get('accepted'):
                print(f"    -> SKIPPED (not accepted)")
                continue
            original_idx = idx_map[i]
            print(f"    -> ACCEPTED. Original mask index: {original_idx}")
            mask_dict = masks[original_idx].copy()
            confidence = float(np.clip(dec.get('confidence', 0.0), 0.0, 1.0))
            mask_dict['confidence'] = confidence
            mask_dict['class'] = dec.get('class')
            if 'area' not in mask_dict and 'segmentation' in mask_dict:
                mask_dict['area'] = int(np.sum(mask_dict['segmentation']))
            bx = mask_dict.get('bbox', [0,0,0,0])
            if len(bx) == 4 and (bx[2] <= W and bx[3] <= H):
                x1, y1, w, h = bx
                bbox_xyxy = [int(x1), int(y1), int(x1 + w), int(y1 + h)]
            else:
                bbox_xyxy = [int(bx[0]), int(bx[1]), int(bx[2]), int(bx[3])]
            cls_label = dec.get('class')
            try:
                cls_label = str(cls_label) if cls_label is not None else "__unknown__"
            except Exception:
                cls_label = "__unknown__"
            print(f"    -> Appending candidate: class='{cls_label}', confidence={confidence:.3f}")
            candidates.append({
                'mask': mask_dict['segmentation'].astype(bool),
                'bbox_xyxy': bbox_xyxy,
                'confidence': confidence,
                'area': int(mask_dict['area']),
                'class': cls_label,
            })
        from collections import Counter
        print("NMS candidates by class:", Counter([c.get('class') for c in candidates]))
        kept = self._nms(candidates, class_aware=True)
        for e in kept:
            seg = e['mask']
            x1, y1, x2, y2 = e['bbox_xyxy']
            bbox_xywh = [int(x1), int(y1), int(x2 - x1), int(y2 - y1)]
            mask_dict = {
                'segmentation': seg,
                'bbox': bbox_xywh,
                'area': int(seg.sum()),
                'confidence': float(e['confidence']),
                'class': e.get('class')
            }
            found.append({
                'mask': mask_dict,
                'confidence': float(e['confidence']),
                'bbox': bbox_xywh,
                'class': e.get('class')
            })
            result_masks.append(mask_dict)
        timing_info['result_formatting'] = time.time() - t_result
        print("1Ô∏è‚É£5Ô∏è‚É£ –®–∞–≥ 11: ResultSaver.save_all_results() - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤")
        t_saving = time.time()
        image_name = Path(image_path).name
        saved_files = self.result_saver.save_all_results(
            image_np, 
            result_masks, 
            output_dir, 
            image_name,
            pipeline_config={"backend": self.mask_backend}
        )
        timing_info['result_saving'] = time.time() - t_saving
        total_time = time.time() - t_total
        timing_info['total_time'] = total_time
        print(f"üéØ –ü—Ä–∏–Ω—è—Ç–æ –º–∞—Å–æ–∫: {len(found)} (–ø–æ—Å–ª–µ –ø—Ä–∞–≤–∏–ª –∏ NMS)")
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
        print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(saved_files)}")
        self._print_timing_statistics(timing_info)
        return {
            "found_elements": found, 
            "masks": result_masks,
            "timing_info": timing_info,
            "output_directory": output_dir,
            "saved_files": saved_files
        }

    def _mask_iou(self, mask_a, mask_b):
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ IoU –¥–ª—è –º–∞—Å–æ–∫."""
        intersection = np.logical_and(mask_a, mask_b).sum()
        union = np.logical_or(mask_a, mask_b).sum()
        return intersection / union if union > 0 else 0.0

    def _nms(self, elements, class_aware=True, class_thresholds=None):
        """–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è NMS —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π."""
        if not elements:
            return []
        
        try:
            import torch
            import torchvision.ops as ops
            use_torch = True
        except ImportError:
            use_torch = False
            
        from collections import defaultdict
        
        def _class_key(v):
            if v is None:
                return "__unknown__"
            try:
                return str(v)
            except Exception:
                return repr(v)
        
        groups = defaultdict(list)
        if class_aware:
            for el in elements:
                groups[_class_key(el.get('class'))].append(el)
        else:
            groups["__all__"] = list(elements)
        
        kept_all = []
        for cls_key, group in groups.items():
            if not group:
                continue
                
            iou_thr = (class_thresholds or {}).get(cls_key, self.nms_iou)
            
            if use_torch and len(group) > 10:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º torch –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø
                kept_cls = self._nms_torch(group, iou_thr)
            else:
                kept_cls = self._nms_numpy(group, iou_thr)
                
            kept_all.extend(kept_cls)
        
        return kept_all
    
    def _nms_torch(self, elements, iou_threshold):
        """NMS —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º torchvision –¥–ª—è bbox + –º–∞—Å–∫–∏."""
        import torch
        import torchvision.ops as ops
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º bbox –∏ scores
        boxes = []
        scores = []
        for el in elements:
            x1, y1, x2, y2 = el['bbox_xyxy']
            boxes.append([x1, y1, x2, y2])
            scores.append(el.get('confidence', 0.0))
        
        boxes_tensor = torch.tensor(boxes, dtype=torch.float32)
        scores_tensor = torch.tensor(scores, dtype=torch.float32)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º bbox NMS
        keep_indices = ops.nms(boxes_tensor, scores_tensor, iou_threshold)
        bbox_kept = [elements[i] for i in keep_indices.tolist()]
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∞—Å–∫–∞–º –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        if len(bbox_kept) <= 1:
            return bbox_kept
            
        final_kept = []
        for i, current in enumerate(bbox_kept):
            should_keep = True
            current_mask = current['mask']
            
            for j in range(i):
                if j < len(final_kept):
                    other_mask = final_kept[j]['mask']
                    if self._mask_iou(current_mask, other_mask) >= iou_threshold:
                        should_keep = False
                        break
            
            if should_keep:
                final_kept.append(current)
                
        return final_kept
    
    def _nms_numpy(self, elements, iou_threshold):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è numpy —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è NMS."""
        if len(elements) <= 1:
            return elements
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence
        sorted_elements = sorted(elements, key=lambda e: float(e.get('confidence', 0.0)), reverse=True)
        
        kept = []
        masks_kept = []
        
        for current in sorted_elements:
            current_mask = current['mask']
            should_keep = True
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IoU —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏ –º–∞—Å–∫–∞–º–∏
            for kept_mask in masks_kept:
                if self._mask_iou(current_mask, kept_mask) >= iou_threshold:
                    should_keep = False
                    break
            
            if should_keep:
                kept.append(current)
                masks_kept.append(current_mask)
                
        return kept

    def _load_example_images(self, dir_path):

        if not dir_path or not Path(dir_path).exists():
            return []
        images = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            for img_path in Path(dir_path).glob(ext):
                try:
                    img = Image.open(img_path).convert('RGB')
                    images.append(img)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_path}: {e}")
        return images
    
    
    def _load_positive_by_class(self, dir_path):
        from pathlib import Path
        from PIL import Image
        result = {}
        if not dir_path or not Path(dir_path).exists():
            return result
        subdirs = [p for p in Path(dir_path).iterdir() if p.is_dir()]
        if not subdirs:
            result['object'] = self._load_example_images(dir_path)
            return result
        for sd in subdirs:
            imgs = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                for img_path in sd.glob(ext):
                    try:
                        imgs.append(Image.open(img_path).convert('RGB'))
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_path}: {e}")
            result[sd.name] = imgs
        return result
    def _print_timing_statistics(self, timing_info):
        print("\n" + "="*60)
        print("‚è±Ô∏è –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–†–ï–ú–ï–ù–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print("="*60)
        total_time = timing_info['total_time']
        stages = [
            ('image_loading', 'üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'),
            ('examples_loading', 'üñºÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤'),
            ('mask_generation', 'üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ (SAM/FastSAM)'),
            ('mask_filtering', 'üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫'),
            ('embedding_extraction', 'üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤'),
            ('scoring_and_decisions', 'üìä –°–∫–æ—Ä–∏–Ω–≥ –∏ —Ä–µ—à–µ–Ω–∏—è'),
            ('result_formatting', 'üìã –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞'),
            ('result_saving', 'üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤')
        ]
        
        for stage_key, stage_name in stages:
            if stage_key in timing_info:
                stage_time = timing_info[stage_key]
                percentage = (stage_time / total_time * 100) if total_time > 0 else 0
                print(f"{stage_name:<40}: {stage_time:>6.3f}—Å ({percentage:>5.1f}%)")
        print("-" * 60)
        print(f"{'üöÄ –û–ë–©–ï–ï –í–†–ï–ú–Ø':<40}: {total_time:>6.3f}—Å (100.0%)")
        print("="*60)
        stage_times = [(name, timing_info.get(key, 0)) for key, name in stages if key in timing_info]
        stage_times.sort(key=lambda x: x[1], reverse=True)
        if len(stage_times) > 1:
            print("\nüêå –°–ê–ú–´–ï –ú–ï–î–õ–ï–ù–ù–´–ï –≠–¢–ê–ü–´:")
            for i, (name, stage_time) in enumerate(stage_times[:3]):
                percentage = (stage_time / total_time * 100) if total_time > 0 else 0
                print(f"   {i+1}. {name}: {stage_time:.3f}—Å ({percentage:.1f}%)")
        if 'mask_generation' in timing_info and timing_info['mask_generation'] > total_time * 0.5:
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
            print("   ‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫ –∑–∞–Ω–∏–º–∞–µ—Ç >50% –≤—Ä–µ–º–µ–Ω–∏")
            print("   ‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ FastSAM –≤–º–µ—Å—Ç–æ SAM-HQ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
            print("   ‚Ä¢ –ò–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã SAM (points_per_side, imgsz)")
        if 'embedding_extraction' in timing_info and timing_info['embedding_extraction'] > total_time * 0.3:
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
            print("   ‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–Ω–∏–º–∞–µ—Ç >30% –≤—Ä–µ–º–µ–Ω–∏")
            print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä feature map (SEARCHDET_FEAT_SHORT_SIDE)")
            print("   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è")
        print()
class Detector:
    def __init__(self, sam_encoder: str, sam_checkpoint: str, sam2_checkpoint: str, 
                 backbone: str = 'dinov2_b', layer: str = 'layer3', 
                 feat_short_side: int = 512, dinov3_ckpt: str = None):
        # –ó–∞–≥—Ä—É–∑–∫–∞ SAM
        self.sam_predictor = SAMPredictor(sam_encoder, sam_checkpoint, sam2_checkpoint)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        if backbone == 'resnet101':
            self.embedding_model = ResNet101Embedding(layer=layer)
        elif backbone.startswith('dinov2'):
            self.embedding_model = DINOv2Embedding(backbone=backbone)
        elif backbone == 'dinov3_convnext_base':
            self.embedding_model = DINOv3Embedding(dinov3_ckpt)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—ç–∫–µ–Ω–¥: {backbone}")

        self.backbone = backbone