#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ð•Ð´Ð¸Ð½Ñ‹Ð¹ ÑÐ½ÐºÐ¾Ð´ÐµÑ€ DINOv3 Ð´Ð»Ñ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°:
- ViT: vitb16 / vitl16 / vith14 (global_pool="token", pooling='cls' Ð¸Ð»Ð¸ 'mean')
- ConvNeXt: convnext_{tiny,small,base,large} (global_pool="avg")

ÐœÐµÑ‚Ð¾Ð´Ñ‹:
- encode_image(PIL.Image) -> (D,)
- encode_mask(image_np, mask_bool) -> (D,)  # Ð¼Ð°ÑÐºÐ° Ð±Ð¸Ð½Ð°Ñ€Ð½Ð°Ñ Ð½Ð° Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸
"""

from __future__ import annotations
import os
from typing import Dict, Optional

import numpy as np
from PIL import Image, ImageOps

import torch
import torch.nn.functional as F
import timm
from timm.data import resolve_model_data_config, create_transform


VIT_BACKBONES: Dict[str, str] = {
    "dinov3_vitb16": "vit_base_patch16_224",
    "dinov3_vitl16": "vit_large_patch16_224",
    "dinov3_vith14": "vit_huge_patch14_224",
    # ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ñ‹
    "vitb16": "vit_base_patch16_224",
    "vitl16": "vit_large_patch16_224",
    "vith14": "vit_huge_patch14_224",
}
CONVN_BACKBONES: Dict[str, str] = {
    "dinov3_convnext_tiny":  "convnext_tiny",
    "dinov3_convnext_small": "convnext_small",
    "dinov3_convnext_base":  "convnext_base",
    "dinov3_convnext_large": "convnext_large",
    # ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ
    "convnext_tiny":  "convnext_tiny",
    "convnext_small": "convnext_small",
    "convnext_base":  "convnext_base",
    "convnext_large": "convnext_large",
}
ALL_BACKBONES = set(VIT_BACKBONES.keys()) | set(CONVN_BACKBONES.keys())


def _load_pil(path: str) -> Optional[Image.Image]:
    try:
        im = Image.open(path).convert("RGB")
        return ImageOps.exif_transpose(im)
    except Exception:
        return None


def _infer_vit_arch_from_state_dict(sd: dict) -> Optional[str]:
    dim = None
    patch = None
    if "cls_token" in sd:
        dim = sd["cls_token"].shape[-1]
    elif "pos_embed" in sd:
        dim = sd["pos_embed"].shape[-1]
    if "patch_embed.proj.weight" in sd:
        w = sd["patch_embed.proj.weight"]
        dim = w.shape[0]
        patch = w.shape[-1]
    if dim == 768 and (patch in (None, 16)):
        return "vit_base_patch16_224"
    if dim == 1024 and (patch in (None, 16)):
        return "vit_large_patch16_224"
    if dim == 1280 and (patch in (None, 14)):
        return "vit_huge_patch14_224"
    return None


class DinoV3Encoder:
    def __init__(
        self,
        backbone: str,
        ckpt: Optional[str],
        device: str = "cuda",
        half: bool = False,
        vit_pooling: str = "cls",  # 'cls' | 'mean'
        use_half: bool = False,
        loader: str = "timm",  # "timm" | "hub"
        repo_dir: Optional[str] = None,
    ):
        if backbone not in ALL_BACKBONES:
            raise ValueError(f"Unknown DINOv3 backbone '{backbone}'")
        self.backbone = backbone
        self.is_vit = backbone in VIT_BACKBONES
        self.arch = VIT_BACKBONES.get(backbone, CONVN_BACKBONES.get(backbone))
        self.device = torch.device(device if device == "cpu" or torch.cuda.is_available() else "cpu")
        self.half = bool(half or use_half)  # ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¾Ð±Ð¾Ð¸Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
        self.use_half = self.half  # Ð£Ð½Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ
        self.vit_pooling = vit_pooling.lower().strip()
        self.loader = loader
        self.repo_dir = repo_dir

        if self.loader == "hub":
            self._build_from_hub(backbone, ckpt)
        else:
            self._build_from_timm(backbone, ckpt)

    def _build_from_timm(self, backbone: str, ckpt: Optional[str]):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‡ÐµÑ€ÐµÐ· timm (Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±)."""
        gp = "token" if self.is_vit else "avg"
        self.model = timm.create_model(self.arch, pretrained=False, num_classes=0, global_pool=gp)
        self.model.eval().to(self.device)
        if self.half and self.device.type == "cuda":
            self.model.half()
        else:
            self.half = False  # ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐ°: Ð½Ð° CPU Ñ‚Ð¾Ð»ÑŒÐºÐ¾ float32

        self.data_cfg = resolve_model_data_config(self.model)
        self.tf = create_transform(**self.data_cfg, is_training=False)

        if ckpt:
            self._smart_load(ckpt)

    def _build_from_hub(self, backbone: str, ckpt: str):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‡ÐµÑ€ÐµÐ· torch.hub (Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±)."""
        if self.repo_dir is None:
            raise ValueError("Ð”Ð»Ñ loader=hub Ð½ÑƒÐ¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ repo_dir (Ð¿ÑƒÑ‚ÑŒ Ðº Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÐºÐ»Ð¾Ð½Ñƒ DINOv3).")

        # ÐšÐ°Ñ€Ñ‚Ð° Ð¸Ð¼Ñ‘Ð½ hub-Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹
        HUB_NAME = None
        if   backbone in ("vitb16", "vit_base_patch16_224"):     HUB_NAME = "dinov3_vitb16"
        elif backbone in ("vitl16", "vit_large_patch16_224"):    HUB_NAME = "dinov3_vitl16"
        elif backbone in ("vith14", "vit_huge_patch14_224"):     HUB_NAME = "dinov3_vith16plus"  # Ð±Ð»Ð¸Ð¶. Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚
        elif backbone in ("convnext_tiny",):                     HUB_NAME = "dinov3_convnext_tiny"
        elif backbone in ("convnext_small",):                    HUB_NAME = "dinov3_convnext_small"
        elif backbone in ("convnext_base", "dinov3_convnext_base"): HUB_NAME = "dinov3_convnext_base"
        elif backbone in ("convnext_large",):                    HUB_NAME = "dinov3_convnext_large"
        else:
            raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ backbone Ð´Ð»Ñ hub: {backbone}")

        print(f"ðŸ§© Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· torch.hub: {HUB_NAME}")
        self.model = torch.hub.load(self.repo_dir, HUB_NAME, source="local", weights=ckpt)
        self.model.eval().to(self.device)
        if self.half:
            self.model.half()

        # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð²Ð·ÑÑ‚ÑŒ data_config Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸; ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ â€” Ð´ÐµÑ„Ð¾Ð»Ñ‚Ñ‹ ImageNet
        try:
            self.data_cfg = resolve_model_data_config(self.model)
            self.tf = create_transform(**self.data_cfg, is_training=False)
        except Exception:
            from torchvision import transforms
            self.tf = transforms.Compose([
                transforms.Resize(224, interpolation=3),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
            ])

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð¼, ViT ÑÑ‚Ð¾ Ð¸Ð»Ð¸ ConvNeXt, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ pooling Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
        name = self.model.__class__.__name__.lower()
        self.is_vit = ("vit" in name)
        print(f"   âš™ï¸ HUB Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {self.model.__class__.__name__} (is_vit={self.is_vit})")

    def _smart_load(self, path: str):
        if not os.path.isfile(path):
            print(f"âš ï¸ DINOv3 ckpt not found: {path}")
            return
        print(f"ðŸ”§ Loading DINOv3 ckpt: {path}")
        sd = torch.load(path, map_location="cpu")
        if isinstance(sd, dict):
            sd = sd.get("state_dict", sd.get("model", sd))

        # drop heads & training wrappers
        cleaned = {}
        drop_prefixes = [
            "head", "fc", "classifier", "pre_logits",
            "seg_head", "decode_head", "aux_head",
            "mask_head", "detr_head", "m2f_head", "linear_head",
            "teacher", "student",
        ]
        for k, v in sd.items():
            if k.startswith("module."):
                k = k[7:]
            if any(k.startswith(p) for p in drop_prefixes):
                continue
            cleaned[k] = v

        if self.is_vit:
            inferred = _infer_vit_arch_from_state_dict(cleaned)
            if inferred and inferred != self.arch:
                print(f"â„¹ï¸ Auto-detect arch: {inferred} (rebuild)")
                gp = "token"
                self.arch = inferred
                self.model = timm.create_model(self.arch, pretrained=False, num_classes=0, global_pool=gp)
                self.model.eval().to(self.device)
                if self.half and self.device.type == "cuda":
                    self.model.half()
                else:
                    self.half = False  # ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²ÐºÐ°: Ð½Ð° CPU Ñ‚Ð¾Ð»ÑŒÐºÐ¾ float32
                self.data_cfg = resolve_model_data_config(self.model)
                self.tf = create_transform(**self.data_cfg, is_training=False)

        missing, unexpected = self.model.load_state_dict(cleaned, strict=False)
        if unexpected:
            print(f"   â„¹ï¸ unexpected keys: {len(unexpected)}")
        if missing:
            print(f"   â„¹ï¸ missing keys   : {len(missing)}")
        print("   âœ… weights loaded (strict=False)")

    @torch.no_grad()
    def _prep(self, img: Image.Image) -> torch.Tensor:
        x = self.tf(img).unsqueeze(0)
        if self.half:
            x = x.half()
        return x.to(self.device)

    @torch.no_grad()
    def encode_image(self, img: Image.Image) -> np.ndarray:
        x = self._prep(img)
        feats = self.model.forward_features(x)

        vec = None
        if hasattr(self.model, "forward_head"):
            out = self.model.forward_head(feats, pre_logits=True)
            if out.ndim == 2:
                vec = out[0]
            elif out.ndim == 3:
                if self.vit_pooling == "mean" and out.shape[1] > 1:
                    vec = out[0, 1:].mean(dim=0)
                else:
                    vec = out[0, 0]
        if vec is None:
            t = feats["x"] if isinstance(feats, dict) and "x" in feats else feats
            if t.ndim == 3:  # ViT
                if self.vit_pooling == "mean" and t.shape[1] > 1:
                    vec = t[0, 1:].mean(dim=0)
                else:
                    vec = t[0, 0]
            elif t.ndim == 4:  # ConvNeXt
                vec = t.mean(dim=(2, 3))[0]
            else:
                vec = t.flatten(1)[0]

        vec = F.normalize(vec.float(), dim=0).cpu().numpy().astype(np.float32)
        return vec

    @torch.no_grad()
    def encode_mask(self, image_np: np.ndarray, mask_bool: np.ndarray) -> np.ndarray:
        """ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¸ Ð½Ð°Ð´Ñ‘Ð¶Ð½Ð°Ñ Ð¼Ð°ÑÐºÐ¸Ñ€Ð¾Ð²ÐºÐ°: Ð·Ð°Ð½ÑƒÐ»ÑÐµÐ¼ Ñ„Ð¾Ð½ Ð¸ ÐºÐ¾Ð´Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ°Ðº Ñ†ÐµÐ»Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ."""
        if mask_bool.dtype != np.bool_:
            mask_bool = mask_bool.astype(bool)
        if mask_bool.sum() == 0:
            # Ð¿ÑƒÑÑ‚Ð°Ñ Ð¼Ð°ÑÐºÐ° â†’ Ð½ÑƒÐ»ÐµÐ²Ð¾Ð¹ Ð²ÐµÐºÑ‚Ð¾Ñ€
            return np.zeros(self.model.num_features, dtype=np.float32)

        # Ð´ÐµÐ»Ð°ÐµÐ¼ masked image
        img_masked = image_np.copy()
        img_masked[~mask_bool] = 0
        pil = Image.fromarray(img_masked).convert("RGB")
        
        x = self.tf(pil).unsqueeze(0)
        x = x.to(self.device)
        if self.half:
            x = x.half()
        
        feats = self.model.forward_features(x)

        vec = None
        if hasattr(self.model, "forward_head"):
            out = self.model.forward_head(feats, pre_logits=True)
            if out.ndim == 2:
                vec = out[0]
            elif out.ndim == 3:
                if self.vit_pooling == "mean" and out.shape[1] > 1:
                    vec = out[0, 1:].mean(dim=0)
                else:
                    vec = out[0, 0]
        if vec is None:
            t = feats["x"] if isinstance(feats, dict) and "x" in feats else feats
            if t.ndim == 3:  # ViT
                if self.vit_pooling == "mean" and t.shape[1] > 1:
                    vec = t[0, 1:].mean(dim=0)
                else:
                    vec = t[0, 0]
            elif t.ndim == 4:  # ConvNeXt
                vec = t.mean(dim=(2, 3))[0]
            else:
                vec = t.flatten(1)[0]

        vec = F.normalize(vec.float(), dim=0).cpu().numpy().astype(np.float32)
        return vec
