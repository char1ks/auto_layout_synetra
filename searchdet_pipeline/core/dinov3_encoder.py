import sys
from pathlib import Path
import torch
import torchvision.transforms as T
import torch.nn.functional as F
from PIL import Image
import numpy as np
from typing import Any, Dict, Optional

# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –≤–∫–ª—é—á–∏—Ç—å TF32 –Ω–∞ CUDA (—Å—Ç–∞–±–∏–ª—å–Ω–µ–µ, —á–µ–º fp16)
try:
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
except Exception:
    pass

def _to_pil_any(x: object) -> Image.Image:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø—É—Ç—å/ndarray/tensor/PIL -> PIL RGB."""
    if isinstance(x, Image.Image):
        return x.convert("RGB")
    if isinstance(x, str):
        return Image.open(x).convert("RGB")
    if isinstance(x, np.ndarray):
        arr = x
        if arr.ndim == 2:
            arr = np.stack([arr]*3, axis=-1)
        if arr.dtype != np.uint8:
            # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ 0..255
            if arr.max() <= 1.0:
                arr = (np.clip(arr, 0, 1) * 255).astype(np.uint8)
            else:
                arr = np.clip(arr, 0, 255).astype(np.uint8)
        return Image.fromarray(arr, mode="RGB")
    if isinstance(x, torch.Tensor):
        t = x.detach().cpu()
        if t.ndim == 2:
            t = t.unsqueeze(-1).repeat(1, 1, 3)
        if t.ndim == 3:
            # CHW -> HWC, 0..1 -> 0..255
            if t.shape[0] in (1, 3):
                t = (t.clamp(0, 1) * 255).byte().permute(1, 2, 0).numpy()
            else:
                t = (t.clamp(0, 1) * 255).byte().numpy()
        return Image.fromarray(t, mode="RGB")
    raise TypeError(f"Unsupported image type: {type(x)}")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å –±—ç–∫–µ–Ω–¥–æ–≤ DINOv3 –∏ –≤—ã–±–∏—Ä–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ –∏–º–µ–Ω–∏
try:
    from dinov3.hub import backbones as dino_backbones
except ImportError:
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –¥–æ–±–∞–≤–∏–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ø–∞–ø–∫—É dinov3 –≤ sys.path
    project_root = Path(__file__).resolve().parent.parent.parent
    dinov3_repo_path = project_root
    if str(dinov3_repo_path) not in sys.path:
        sys.path.insert(0, str(dinov3_repo_path))
    inner_dinov3_path = project_root / 'dinov3'
    if str(inner_dinov3_path) not in sys.path:
        sys.path.insert(0, str(inner_dinov3_path))
    from dinov3.hub import backbones as dino_backbones


class DinoV3Encoder:
    def __init__(self, backbone_name='vitb16', device='cpu', ckpt_path=None):
        self.device = torch.device(device if (device == "cpu" or torch.cuda.is_available()) else "cpu")
        # –§–æ—Ä—Å–∏–º fp32: –ª—é–±—ã–µ half-—Ä–µ–∂–∏–º—ã —á–∞—Å—Ç–æ –¥–∞—é—Ç NaN –Ω–∞ ViT
        self.half = False
        self.pooling = "cls"
        self.is_vit = True

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –±—ç–∫–µ–Ω–¥–∞ –∏ –≤—ã–±–µ—Ä–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
        name = (backbone_name or 'vitb16').lower()
        # –†–∞–∑—Ä–µ—à–∏–º —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∞–ª–∏–∞—Å—ã
        aliases = {
            'vits16': 'dinov3_vits16',
            'vits16plus': 'dinov3_vits16plus',
            'vitb16': 'dinov3_vitb16',
            'vitl16': 'dinov3_vitl16',
            'vitl16plus': 'dinov3_vitl16plus',
            'vith16plus': 'dinov3_vith16plus',
            'vit7b16': 'dinov3_vit7b16',
            'convnext_tiny': 'dinov3_convnext_tiny',
            'convnext_small': 'dinov3_convnext_small',
            'convnext_base': 'dinov3_convnext_base',
            'convnext_large': 'dinov3_convnext_large',
        }
        # –ï—Å–ª–∏ –∏–º—è —É–∂–µ –≤ –ø–æ–ª–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å
        if name in aliases:
            fn_name = aliases[name]
        elif name.startswith('dinov3_'):
            fn_name = name
        else:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –∏–∑ –∏–º–µ–Ω–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if 'vit7b16' in name:
                fn_name = 'dinov3_vit7b16'
            elif 'vitb16' in name:
                fn_name = 'dinov3_vitb16'
            elif 'vits16plus' in name:
                fn_name = 'dinov3_vits16plus'
            elif 'vits16' in name:
                fn_name = 'dinov3_vits16'
            elif 'vitl16plus' in name:
                fn_name = 'dinov3_vitl16plus'
            elif 'vitl16' in name:
                fn_name = 'dinov3_vitl16'
            elif 'vith16plus' in name:
                fn_name = 'dinov3_vith16plus'
            elif 'convnext_large' in name:
                fn_name = 'dinov3_convnext_large'
            elif 'convnext_base' in name:
                fn_name = 'dinov3_convnext_base'
            elif 'convnext_small' in name:
                fn_name = 'dinov3_convnext_small'
            elif 'convnext_tiny' in name:
                fn_name = 'dinov3_convnext_tiny'
            else:
                fn_name = 'dinov3_vitb16'
        self.is_vit = not fn_name.startswith('dinov3_convnext')

        if not hasattr(dino_backbones, fn_name):
            print(f"‚ö†Ô∏è DINOv3: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π backbone '{backbone_name}', –∏—Å–ø–æ–ª—å–∑—É–µ–º vitb16")
            fn_name = 'dinov3_vitb16'
        backbone_fn = getattr(dino_backbones, fn_name)
        print(f"üîß DINOv3: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É {fn_name}")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        if ckpt_path:
            print(f"üîß DINOv3: –∑–∞–≥—Ä—É–∂–∞–µ–º checkpoint –∏–∑ {ckpt_path}")
            self.model = backbone_fn(pretrained=False).to(self.device)
            ckpt = torch.load(ckpt_path, map_location=self.device)
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å state_dict –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π
            if isinstance(ckpt, dict):
                if 'model' in ckpt and isinstance(ckpt['model'], dict):
                    state_dict = ckpt['model']
                    print(f"   üì¶ –ò–∑–≤–ª–µ–∫–ª–∏ state_dict –∏–∑ –∫–ª—é—á–∞ 'model'")
                elif 'state_dict' in ckpt and isinstance(ckpt['state_dict'], dict):
                    state_dict = ckpt['state_dict']
                    print(f"   üì¶ –ò–∑–≤–ª–µ–∫–ª–∏ state_dict –∏–∑ –∫–ª—é—á–∞ 'state_dict'")
                elif 'backbone' in ckpt and isinstance(ckpt['backbone'], dict):
                    state_dict = ckpt['backbone']
                    print(f"   üì¶ –ò–∑–≤–ª–µ–∫–ª–∏ state_dict –∏–∑ –∫–ª—é—á–∞ 'backbone'")
                else:
                    # –í–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ —É–∂–µ state_dict
                    state_dict = {k: v for k, v in ckpt.items() if isinstance(v, torch.Tensor)}
                    print(f"   üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpoint –∫–∞–∫ state_dict –Ω–∞–ø—Ä—è–º—É—é")
            else:
                state_dict = ckpt
                print(f"   üì¶ Checkpoint –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–ª—é—á–µ–π –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
            model_keys = set(self.model.state_dict().keys())
            ckpt_keys = set(state_dict.keys())
            matching_keys = model_keys & ckpt_keys
            
            print(f"   üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç {len(model_keys)} –∫–ª—é—á–µ–π, checkpoint - {len(ckpt_keys)}")
            print(f"   üîç –°–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∫–ª—é—á–µ–π: {len(matching_keys)} –∏–∑ {len(model_keys)}")
            
            if len(matching_keys) < len(model_keys) * 0.1:  # –ú–µ–Ω–µ–µ 10% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                print(f"   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –û—á–µ–Ω—å –º–∞–ª–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∫–ª—é—á–µ–π ({len(matching_keys)}/{len(model_keys)})!")
                print(f"   ‚ùå –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ checkpoint –Ω–µ –¥–ª—è backbone DINOv3, –∞ –¥–ª—è –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, DETR head)")
                print(f"   ‚ùå –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π backbone checkpoint –∏–ª–∏ —É–±—Ä–∞—Ç—å --dinov3-ckpt")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                print(f"   üîç –ü—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π –º–æ–¥–µ–ª–∏: {list(model_keys)[:5]}")
                print(f"   üîç –ü—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π checkpoint: {list(ckpt_keys)[:5]}")

            # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å –æ—Å–ª–∞–±–ª–µ–Ω–Ω—ã–º —Å—Ç—Ä–æ–≥–∏–º —Ä–µ–∂–∏–º–æ–º –∏ –≤—ã–≤–µ–¥–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            missing, unexpected = self.model.load_state_dict(state_dict, strict=False)
            try:
                n_total = sum(p.numel() for p in self.model.state_dict().values())
                n_loaded = sum(state_dict[k].numel() for k in self.model.state_dict().keys() if k in state_dict)
                load_percentage = (n_loaded / n_total) * 100 if n_total > 0 else 0
                print(f"   üì¶ DINOv3 ckpt: –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ~{n_loaded}/{n_total} ({load_percentage:.1f}%)")
                print(f"   üì¶ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª—é—á–µ–π: {len(missing)}, –ª–∏—à–Ω–∏—Ö –∫–ª—é—á–µ–π: {len(unexpected)}")
                
                if len(missing) > 0:
                    print(f"   ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏ (–ø–µ—Ä–≤—ã–µ 5): {list(missing)[:5]}")
                if len(unexpected) > 0:
                    print(f"   ‚ö†Ô∏è –õ–∏—à–Ω–∏–µ –∫–ª—é—á–∏ (–ø–µ—Ä–≤—ã–µ 5): {list(unexpected)[:5]}")
                    
                if load_percentage < 50:
                    print(f"   ‚ùå –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–µ–Ω–µ–µ 50% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤! –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.")
                    print(f"   ‚ùå –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å checkpoint —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π {fn_name}")
                    
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        else:
            print(f"üîß DINOv3: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –∏–∑ hub")
            self.model = backbone_fn(pretrained=True).to(self.device)

        # –í–ê–ñ–ù–û: –¥–µ—Ä–∂–∏–º –≤–µ—Å–∞ –≤ float32
        self.model.eval().float()

        self.transform = T.Compose([
            T.Resize(224),
            T.CenterCrop(224),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def _compute_dtype(self):
        """–ö–∞–∫–æ–π dtype —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è—Ö."""
        if self.device.type == "cuda" and hasattr(self, 'half') and self.half:
            return torch.float16
        return torch.float32

    @staticmethod
    def _pick_feature(feats: Any, pooling: str = "cls") -> torch.Tensor:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä [B,D] –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–∞—é—Ç ViT/ConvNeXt –≤ DINOv3.
        –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:
          - dict['x_norm_clstoken'] (–≥–æ—Ç–æ–≤—ã–π cls)
          - dict['x_prenorm'][:,0]  (cls –¥–æ –≥–æ–ª–æ–≤—ã)
          - dict['x_norm_patchtokens'].mean(dim=1) (mean –ø–æ –ø–∞—Ç—á–∞–º)
          - dict['x'] (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
          - –ø—Ä–æ—Å—Ç–æ —Ç–µ–Ω–∑–æ—Ä (–µ—Å–ª–∏ –Ω–µ dict)
        """
        if isinstance(feats, dict):
            if 'x_norm_clstoken' in feats:
                z = feats['x_norm_clstoken']           # [B,D]
            elif 'x_prenorm' in feats:
                z = feats['x_prenorm']
                if z.ndim == 3:                        # [B,T,D]
                    z = z[:, 0, :]                     # cls
            elif 'x_norm_patchtokens' in feats:
                z = feats['x_norm_patchtokens']        # [B,T,D]
                if z.ndim == 3:
                    z = z[:, 1:, :].mean(dim=1) if z.shape[1] > 1 else z[:, 0, :]
            elif 'x' in feats:
                z = feats['x']
                if z.ndim == 4:                        # ConvNeXt [B,C,H,W]
                    z = z.mean(dim=(2,3))
                elif z.ndim == 3:                      # [B,T,D]
                    z = z[:, 0, :] if pooling == "cls" else z[:, 1:, :].mean(dim=1)
                elif z.ndim == 2:
                    pass
                else:
                    z = z.flatten(1)
            else:
                # –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π dict -> —Å–≤–∞–ª–∏–≤–∞–µ–º—Å—è –≤ mean –ø–æ –≤—Å–µ–º —Ç–µ–Ω–∑–æ—Ä–∞–º
                vs = []
                for v in feats.values():
                    if torch.is_tensor(v):
                        vv = v
                        if vv.ndim == 4: vv = vv.mean(dim=(2,3))
                        if vv.ndim == 3: vv = vv.mean(dim=1)
                        if vv.ndim == 2: vs.append(vv)
                z = torch.stack(vs, dim=0).mean(dim=0) if vs else None
        else:
            z = feats

        if not torch.is_tensor(z):
            raise RuntimeError("DINOv3: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ forward_features()")

        if z.ndim == 4:  # [B,C,H,W]
            z = z.mean(dim=(2,3))
        elif z.ndim == 3:  # [B,T,D]
            z = z[:, 0, :] if pooling == "cls" else z[:, 1:, :].mean(dim=1)
        elif z.ndim == 1:
            z = z[None, :]
        return z  # [B,D]

    # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å
    @torch.no_grad()
    def _prep(self, img_pil):
        x = self.transform(img_pil).unsqueeze(0)         # [1,3,H,W]
        x = x.to(self.device, dtype=torch.float32)
        return x

    @torch.no_grad()
    def _prep_tensor(self, img_pil: Image.Image) -> torch.Tensor:
        """PIL -> (1,3,H,W) –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º device –∏ —Å dtype –º–æ–¥–µ–ª–∏."""
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê _prep_tensor: PIL —Ä–∞–∑–º–µ—Ä = {img_pil.size}")
        
        x = self.transform(img_pil).unsqueeze(0)            # float32 CPU
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        x_has_nan = torch.isnan(x).any()
        x_has_inf = torch.isinf(x).any()
        x_min, x_max = x.min().item(), x.max().item()
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê _prep_tensor: –ü–æ—Å–ª–µ transform {x.shape}, NaN={x_has_nan}, Inf={x_has_inf}, min={x_min:.4f}, max={x_max:.4f}")
        
        x = x.to(self.device)
        wanted_dtype = next(self.model.parameters()).dtype
        if x.dtype != wanted_dtype:
            x = x.to(dtype=wanted_dtype)             # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º precision —Å –º–æ–¥–µ–ª—å—é
        return x

    @torch.no_grad()
    def _forward_safe(self, x: torch.Tensor) -> torch.Tensor:
        """–ï–¥–∏–Ω—ã–π –ø—É—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ -> L2-–Ω–æ—Ä–º (B,D), float32 CPU."""
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
        x_has_nan = torch.isnan(x).any()
        x_has_inf = torch.isinf(x).any()
        x_min, x_max = x.min().item(), x.max().item()
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê _forward_safe: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä {x.shape}, NaN={x_has_nan}, Inf={x_has_inf}, min={x_min:.4f}, max={x_max:.4f}")
        
        if x_has_nan or x_has_inf:
            print(f"   ‚ùå –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç NaN/Inf, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –Ω—É–ª–∏")
            x = torch.zeros_like(x)
        
        feats = self.model.forward_features(x)
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: model.forward_features –≤–µ—Ä–Ω—É–ª —Ç–∏–ø = {type(feats)}")
        if isinstance(feats, dict):
            print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ö–ª—é—á–∏ –≤ feats = {list(feats.keys())}")
            for k, v in feats.items():
                if isinstance(v, torch.Tensor):
                    v_has_nan = torch.isnan(v).any()
                    v_has_inf = torch.isinf(v).any()
                    print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: feats['{k}'] shape={v.shape}, NaN={v_has_nan}, Inf={v_has_inf}")
        elif isinstance(feats, torch.Tensor):
            feats_has_nan = torch.isnan(feats).any()
            feats_has_inf = torch.isinf(feats).any()
            print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: feats tensor shape={feats.shape}, NaN={feats_has_nan}, Inf={feats_has_inf}")
        
        if hasattr(self.model, "forward_head"):
            z = self.model.forward_head(feats, pre_logits=True)
        else:
            t = feats["x"] if isinstance(feats, dict) and "x" in feats else feats
            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞—â–µ–Ω–∏–µ–º –∫ ndim
            if isinstance(t, dict):
                # –ï—Å–ª–∏ t –≤—Å–µ –µ—â–µ —Å–ª–æ–≤–∞—Ä—å, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–Ω–∑–æ—Ä
                if "x_norm_clstoken" in t:
                    z = t["x_norm_clstoken"]
                elif "x_norm_patchtokens" in t:
                    z = t["x_norm_patchtokens"][:, 0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω
                else:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è, –∫–æ—Ç–æ—Ä–æ–µ —è–≤–ª—è–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä–æ–º
                    tensor_values = [v for v in t.values() if isinstance(v, torch.Tensor)]
                    if tensor_values:
                        z = tensor_values[0]
                        if z.ndim == 3:
                            z = z[:, 0]  # –ë–µ—Ä–µ–º CLS —Ç–æ–∫–µ–Ω
                        elif z.ndim > 2:
                            z = z.flatten(1)
                    else:
                        # Fallback: —Å–æ–∑–¥–∞–µ–º –Ω—É–ª–µ–≤–æ–π —Ç–µ–Ω–∑–æ—Ä
                        z = torch.zeros((x.shape[0], 768), device=x.device, dtype=x.dtype)
            elif hasattr(t, 'ndim'):
                if t.ndim == 4:      # (B,C,H,W) ConvNeXt
                    z = t.mean(dim=(2, 3))
                elif t.ndim == 3:    # (B,T,D) ViT
                    z = t[:, 0]
                else:                # (B,D)
                    z = t.flatten(1)
            else:
                # Fallback –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤
                z = torch.zeros((x.shape[0], 768), device=x.device, dtype=x.dtype)

        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ z –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        z_has_nan = torch.isnan(z).any()
        z_has_inf = torch.isinf(z).any()
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: z –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è shape={z.shape}, NaN={z_has_nan}, Inf={z_has_inf}")
        
        z = z.float()
        # –∑–∞–ø–æ–º–Ω–∏–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ–¥–∏–Ω —Ä–∞–∑
        if not hasattr(self, "feat_dim"):
            self.feat_dim = int(z.shape[-1])

        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        z_norm_before = torch.norm(z, dim=-1)
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê DINOv3: –ù–æ—Ä–º–∞ –¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ = {z_norm_before.item():.8f}")
        
        z = F.normalize(z, dim=-1, eps=1e-6)
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        z_norm_after = torch.norm(z, dim=-1)
        print(f"   üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê DINOv3: –ù–æ—Ä–º–∞ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ = {z_norm_after.item():.8f}")
        
        return z.cpu()

    @torch.no_grad()
    def _forward_features_safe(self, x: torch.Tensor) -> torch.Tensor:
        """
        –ñ—ë—Å—Ç–∫–∏–π fp32-–ø—É—Ç—å + —Å–∞–Ω–∞—Ü–∏—è NaN. –ü—Ä–∏ NaN –Ω–∞ GPU ‚Äî –ø–æ–≤—Ç–æ—Ä—è–µ–º –Ω–∞ CPU.
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ –Ω–æ—Ä–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞ –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é –ø—Ä–∏ CLS-–ø—É–ª–∏–Ω–≥–µ ‚Äî
        –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π MEAN-–ø—É–ª–∏–Ω–≥ –ø–æ –ø–∞—Ç—á–∞–º –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [D] (–¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è).
        """
        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ–≥–æ–Ω –Ω–∞ —Ç–µ–∫—É—â–µ–º –¥–µ–≤–∞–π—Å–µ –≤ float32 –±–µ–∑ autocast
        self.model.float().eval()
        x = x.to(self.device, dtype=torch.float32)

        feats = self.model.forward_features(x)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫ CLS –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π MEAN –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ forward
        z_cls = self._pick_feature(feats, pooling="cls")  # [1,D]
        z_mean = self._pick_feature(feats, pooling="mean")  # [1,D]

        # –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ NaN/Inf
        need_cpu_retry = (not torch.isfinite(z_cls).all()) or (not torch.isfinite(z_mean).all())
        if need_cpu_retry:
            # –ø–æ–≤—Ç–æ—Ä –Ω–∞ CPU ‚Üí float32
            cpu = torch.device("cpu")
            self.model = self.model.to(cpu, dtype=torch.float32).eval()
            x_cpu = x.to(cpu, dtype=torch.float32)
            feats = self.model.forward_features(x_cpu)
            z_cls = self._pick_feature(feats, pooling="cls")
            z_mean = self._pick_feature(feats, pooling="mean")

        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å–∞–Ω–∞—Ü–∏—è
        z_cls = torch.nan_to_num(z_cls, nan=0.0, posinf=0.0, neginf=0.0).float()
        z_mean = torch.nan_to_num(z_mean, nan=0.0, posinf=0.0, neginf=0.0).float()

        # –ü–æ—Å—á–∏—Ç–∞–µ–º –Ω–æ—Ä–º—ã –¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –≤—ã–≤–µ–¥–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
        n_cls = torch.norm(z_cls, dim=-1).item()
        n_mean = torch.norm(z_mean, dim=-1).item()
        print(f"   üîç DINOv3: –Ω–æ—Ä–º—ã –¥–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ ‚Äî CLS={n_cls:.6f}, MEAN={n_mean:.6f}")

        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ—Ç, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–æ—Ä–º–∞ –≤—ã—à–µ –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–∫–æ–ª–æ-–Ω—É–ª–µ–≤–æ–π
        eps = 1e-6
        if (n_cls < eps) and (n_mean >= eps):
            print("   ‚ö†Ô∏è DINOv3: CLS-–Ω–æ—Ä–º–∞ ~0, –∏—Å–ø–æ–ª—å–∑—É–µ–º MEAN-–ø—É–ª–∏–Ω–≥")
            z = z_mean
        elif (n_mean < eps) and (n_cls >= eps):
            z = z_cls
        else:
            # –ï—Å–ª–∏ –æ–±–∞ –≤–∞–ª–∏–¥–Ω—ã ‚Äî –±–µ—Ä–µ–º —Å –±–æ–ª—å—à–µ–π –Ω–æ—Ä–º–æ–π; –µ—Å–ª–∏ –æ–±–∞ ~0 ‚Äî –≤–æ–∑—å–º—ë–º CLS (–¥–∞–ª—å—à–µ –æ–±–Ω—É–ª–∏—Ç—Å—è –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏)
            z = z_cls if n_cls >= n_mean else z_mean

        # L2-–Ω–æ—Ä–º–∞ (–µ—Å–ª–∏ z ~ 0, –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –Ω—É–ª–µ–≤—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º ‚Äî —ç—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –≤—ã—à–µ –ø–æ —Å—Ç–µ–∫—É)
        z = torch.nn.functional.normalize(z, dim=-1)
        return z[0]  # [D]

    @torch.no_grad()
    def encode(self, img_pil) -> np.ndarray:
        x = self._prep(img_pil)
        z = self._forward_features_safe(x)               # [D], float32
        v = z.detach().cpu().numpy().astype(np.float32)

        # –≤—Ç–æ—Ä–æ–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–≤–µ—Ä–∫–∏
        if not np.isfinite(v).all():
            v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
        # –µ—Å–ª–∏ –Ω–æ—Ä–º–∞ –≤–¥—Ä—É–≥ ~0 (—Ä–µ–¥–∫–æ) ‚Äî –≤–µ—Ä–Ω—ë–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä (–ª—É—á—à–µ, —á–µ–º NaN)
        n = np.linalg.norm(v)
        if not np.isfinite(n) or n < 1e-6:
            v = np.zeros_like(v, dtype=np.float32)
        return v
