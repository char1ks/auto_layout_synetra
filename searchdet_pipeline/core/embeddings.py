# embeddings.py

import os
import glob
import numpy as np
from PIL import Image
import cv2
import torch

from .dinov3_encoder import DinoV3Encoder

def _to_pil_any(x):
    """–ù–∞–¥—ë–∂–Ω–æ –ø—Ä–∏–≤–æ–¥–∏–º –≤—Å—ë –∫ PIL.Image."""
    if isinstance(x, Image.Image):
        return x
    if isinstance(x, str):
        # –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        return Image.open(x).convert("RGB")
    if isinstance(x, np.ndarray):
        if x.ndim == 2:
            x = np.stack([x, x, x], axis=-1)
        if x.dtype != np.uint8:
            x = np.clip(x, 0, 255).astype(np.uint8)
        return Image.fromarray(x, mode="RGB")
    if torch.is_tensor(x):
        t = x.detach().cpu()
        if t.ndim == 3 and t.shape[0] in (1,3):  # [C,H,W] -> [H,W,C]
            t = t.permute(1,2,0).contiguous()
        t = t.numpy()
        return _to_pil_any(t)
    # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    raise TypeError(f"Cannot convert type {type(x)} to PIL.Image")


def _l2n(x: np.ndarray, axis: int = -1, eps: float = 1e-12) -> np.ndarray:
    n = np.linalg.norm(x, axis=axis, keepdims=True)
    return x / np.maximum(n, eps)


def _iter_images(root):
    exts = ("*.jpg", "*.jpeg", "*.png", "*.bmp", "*.webp", "*.tif", "*.tiff")
    paths = []
    for e in exts:
        paths.extend(glob.glob(os.path.join(root, e)))
    return sorted(paths)

def extract_features_from_masks(encoder, masked_crops):
    """
    masked_crops: List[PIL.Image] ‚Äî –≤—ã—Ä–µ–∑–∫–∏ –ø–æ–¥ –º–∞—Å–∫–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: np.ndarray (N,D)
    """
    feats = []
    # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π dtype/device –∏–∑ –º–æ–¥–µ–ª–∏
    p = next(encoder.model.parameters())
    dev, dt = p.device, p.dtype

    for im in masked_crops:
        x = encoder.tf(im).unsqueeze(0)                  # cpu float32
        x = x.to(device=dev, dtype=dt, non_blocking=True)
        with torch.no_grad():
            f = encoder.model.forward_features(x)
            # —Ç–æ—Ç –∂–µ —Å–ø–æ—Å–æ–±, —á—Ç–æ –∏ –≤ encoder.encode
            if hasattr(encoder.model, "forward_head"):
                out = encoder.model.forward_head(f, pre_logits=True)
            else:
                out = f
            if out.ndim == 2:
                v = out[0]
            elif out.ndim == 3:
                if encoder.pooling == "mean" and out.shape[1] > 1:
                    v = out[0, 1:].mean(dim=0)
                else:
                    v = out[0, 0]
            elif out.ndim == 4:
                v = out.mean(dim=(2, 3))[0]
            else:
                v = out.flatten(1)[0]
            v = torch.nn.functional.normalize(v.float(), dim=0)
            feats.append(v.cpu().numpy().astype(np.float32))

    if not feats:
        return np.zeros((0, 1), dtype=np.float32)
    return np.stack(feats, axis=0)  # (N,D)


class EmbeddingExtractor:
    def __init__(self, detector):
        self.detector = detector
        self.encoder = DinoV3Encoder(
            backbone_name=getattr(detector, 'dinov3_backbone', 'vitb16'),
            device=detector.device,
            ckpt_path=getattr(detector, 'dinov3_ckpt', None)
        )

    def _safe_stack(self, arrs, axis=0):
        if not arrs:
            return np.zeros((0, 768), dtype=np.float32)  # –¥–µ—Ñ–æ–ª—Ç D=768, –ø–æ–¥–º–µ–Ω–∏—Ç—Å—è –Ω–∏–∂–µ
        return np.stack(arrs, axis=axis)

    def _filter_bad(self, mat: np.ndarray, cls_name: str = None, kind: str = ""):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å NaN/Inf/–Ω—É–ª–µ–≤–æ–π –Ω–æ—Ä–º–æ–π."""
        if mat.size == 0:
            return mat
        bad = ~np.isfinite(mat).all(axis=1)
        norms = np.linalg.norm(mat, axis=1)
        bad |= (norms < 1e-6)
        if bad.any():
            print(f"   ‚ö†Ô∏è Dropped {bad.sum()} bad {kind} embeddings"
                  + (f" in class '{cls_name}'" if cls_name else ""))
        return mat[~bad]

    def _encode_pil_list(self, pil_list):
        """–ö–æ–¥–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ PIL-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ‚Üí (N,D) –±–µ–∑ NaN."""
        out = []
        for i, im in enumerate(pil_list):
            try:
                v = self.encoder.encode(im)  # (D,)
                if not np.isfinite(v).all():
                    v = np.zeros_like(v, dtype=np.float32)
                out.append(v.astype(np.float32))
            except Exception as e:
                print(f"   ‚ö†Ô∏è Pos/Neg encode failed ({i}): {e}")
        if not out:
            return np.zeros((0, 768), dtype=np.float32)
        M = self._safe_stack(out, axis=0)
        M = self._filter_bad(M, kind="example")
        return M

    # ---------- –ù–ê–î–Å–ñ–ù–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï ROI –ú–ê–°–ö–ò –ß–ï–†–ï–ó DINOv3 ----------
    def _encode_mask_roi_with_dinov3(self, image_np: np.ndarray, mask_bool: np.ndarray, pad: int = 8) -> np.ndarray:
        """
        image_np: HxWx3 (uint8), mask_bool: HxW (bool)
        –í—ã—Ä–µ–∑–∞–µ—Ç bbox(mask) —Å –Ω–µ–±–æ–ª—å—à–∏–º –ø–æ–ª–µ–º, —Ñ–æ–Ω –∑–∞–ª–∏–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–º —Ü–≤–µ—Ç–æ–º, –∫–æ–¥–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ encoder.encode(PIL).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç np.float32 –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (D,) –±–µ–∑ NaN.
        """
        assert image_np.ndim == 3 and image_np.shape[2] == 3, "image_np must be HxWx3"
        H, W, _ = image_np.shape
        mb = mask_bool.astype(bool)
        
        print(f"     üîç ROI –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü–ª–æ—â–∞–¥—å –º–∞—Å–∫–∏ = {mb.sum()} –ø–∏–∫—Å–µ–ª–µ–π –∏–∑ {mb.size}")
        
        if mb.sum() == 0:
            print(f"     ‚ö†Ô∏è ROI: –ü—É—Å—Ç–∞—è –º–∞—Å–∫–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä")
            return np.zeros((getattr(self.encoder, "feat_dim", 768),), dtype=np.float32)

        ys, xs = np.where(mb)
        y0, y1 = max(0, ys.min()-pad), min(H, ys.max()+1+pad)
        x0, x1 = max(0, xs.min()-pad), min(W, xs.max()+1+pad)
        
        print(f"     üîç ROI: Bounding box = ({y0}, {x0}) -> ({y1}, {x1})")

        crop = image_np[y0:y1, x0:x1].copy()
        m_crop = mb[y0:y1, x0:x1]
        
        print(f"     üîç ROI: –†–∞–∑–º–µ—Ä –∫—Ä–æ–ø–∞ = {crop.shape}")

        # –∑–∞–ø–æ–ª–Ω—è–µ–º —Ñ–æ–Ω —Å—Ä–µ–¥–Ω–∏–º —Ü–≤–µ—Ç–æ–º –∏–∑ ROI (—É–º–µ–Ω—å—à–∞–µ—Ç ¬´–∑–∞—Å–≤–µ—Ç¬ª)
        mean_color = crop[m_crop].mean(axis=0) if m_crop.any() else np.array([128,128,128], dtype=np.float32)
        bg = np.tile(mean_color.reshape(1,1,3), (crop.shape[0], crop.shape[1], 1))
        crop = np.where(m_crop[...,None], crop, bg).astype(np.uint8)
        
        print(f"     üîç ROI: –°—Ä–µ–¥–Ω–∏–π —Ü–≤–µ—Ç —Ñ–æ–Ω–∞ = {mean_color}")

        try:
            pil = Image.fromarray(crop, mode="RGB")
            v = self.encoder.encode(pil)
            
            print(f"     üîç ROI: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–µ–∫—Ç–æ—Ä - finite: {np.isfinite(v).all()}, –Ω–æ—Ä–º–∞: {np.linalg.norm(v):.2e}")
            
            if not np.isfinite(v).all():
                print(f"     ‚ö†Ô∏è ROI: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN/Inf, –ø—Ä–∏–º–µ–Ω—è–µ–º nan_to_num")
                v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
                
            n = np.linalg.norm(v)
            if not np.isfinite(n) or n < 1e-6:
                print(f"     ‚ö†Ô∏è ROI: –ù—É–ª–µ–≤–∞—è –Ω–æ—Ä–º–∞ ({n:.2e}), –æ–±–Ω—É–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä")
                v = np.zeros_like(v, dtype=np.float32)
            else:
                print(f"     ‚úÖ ROI: –í–∞–ª–∏–¥–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {n:.2e}")
                
        except Exception as e:
            print(f"     ‚ùå ROI: –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è - {e}")
            import traceback
            traceback.print_exc()
            v = np.zeros((getattr(self.encoder, "feat_dim", 768),), dtype=np.float32)
        return v.astype(np.float32)

    # ---------- –ú–ê–°–ö–ò: –í–°–ï–ì–î–ê –ß–ï–†–ï–ó DINOv3 ----------
    def extract_mask_embeddings(self, image_pil, masks):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É (M,D). –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞—Ä–∏ SAM/FastSAM –∏ ¬´–∫—Ä–æ–ø—ã¬ª.
        –õ—é–±—ã–µ NaN ‚Üí –æ–±–Ω—É–ª—è–µ–º, –ø—É—Å—Ç—ã–µ/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ ‚Üí –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º.
        """
        vecs = []
        image_np = np.array(image_pil)

        for i, m in enumerate(masks):
            print(f"   üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Å–∫—É {i+1}/{len(masks)}, —Ç–∏–ø = {type(m)}")
            try:
                # 1) –°—Ç–∞–Ω–¥–∞—Ä—Ç SAM/FastSAM: {'segmentation': np.ndarray[bool], ...}
                if isinstance(m, dict) and 'segmentation' in m:
                    seg = m['segmentation']
                    if isinstance(seg, np.ndarray):
                        print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: SAM —Ñ–æ—Ä–º–∞—Ç, segmentation shape={seg.shape}, dtype={seg.dtype}")
                        v = self._encode_mask_roi_with_dinov3(image_np, seg.astype(bool), pad=8)
                        print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–æ–ª—É—á–µ–Ω –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(v):.2e}")
                        vecs.append(v.astype(np.float32))
                    else:
                        print(f"   ‚ö†Ô∏è Mask {i+1}: 'segmentation' is not numpy array (type={type(seg)}), skip")
                        continue

                # 2) –û–±—ä–µ–∫—Ç —Å .crop(image) -> –ª—é–±–æ–π —Ç–∏–ø ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL
                elif hasattr(m, "crop"):
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –û–±—ä–µ–∫—Ç —Å .crop() –º–µ—Ç–æ–¥–æ–º")
                    crop_any = m.crop(image_pil)
                    crop_pil = _to_pil_any(crop_any)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: Crop —Ä–∞–∑–º–µ—Ä = {crop_pil.size}")
                    v = self.encoder.encode(crop_pil)
                    v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–æ–ª—É—á–µ–Ω –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(v):.2e}")
                    vecs.append(v)

                # 3) –ü—Ä—è–º—ã–µ –∑–∞–≥–æ—Ç–æ–≤–∫–∏: str/ndarray/tensor/PIL
                elif isinstance(m, (str, np.ndarray, torch.Tensor, Image.Image)):
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü—Ä—è–º–∞—è –∑–∞–≥–æ—Ç–æ–≤–∫–∞, —Ç–∏–ø = {type(m)}")
                    crop_pil = _to_pil_any(m)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ PIL —Ä–∞–∑–º–µ—Ä = {crop_pil.size}")
                    v = self.encoder.encode(crop_pil)
                    v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–æ–ª—É—á–µ–Ω –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(v):.2e}")
                    vecs.append(v)

                # 4) –ö–æ—Ä—Ç–µ–∂–∏ (img, mask) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω–∫—É
                elif isinstance(m, (tuple, list)) and len(m) == 2:
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ö–æ—Ä—Ç–µ–∂/—Å–ø–∏—Å–æ–∫ –∏–∑ 2 —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    crop_pil = _to_pil_any(m[0])
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ PIL —Ä–∞–∑–º–µ—Ä = {crop_pil.size}")
                    v = self.encoder.encode(crop_pil)
                    v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–æ–ª—É—á–µ–Ω –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(v):.2e}")
                    vecs.append(v)

                # 5) –°–ª–æ–≤–∞—Ä–∏ —Å "image"/"crop"
                elif isinstance(m, dict):
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ {list(m.keys())}")
                    crop_any = m.get("image", m.get("crop", None))
                    if crop_any is None:
                        print(f"   ‚ö†Ô∏è Mask {i+1}: dict has no 'image' or 'crop', skip")
                        continue
                    crop_pil = _to_pil_any(crop_any)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ PIL —Ä–∞–∑–º–µ—Ä = {crop_pil.size}")
                    v = self.encoder.encode(crop_pil)
                    v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)
                    print(f"   üîç –ú–∞—Å–∫–∞ {i+1}: –ü–æ–ª—É—á–µ–Ω –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ—Ä–º–æ–π {np.linalg.norm(v):.2e}")
                    vecs.append(v)

                else:
                    print(f"   ‚ö†Ô∏è Mask {i+1}: unknown format {type(m)}, skip")
                    continue

            except Exception as e:
                print(f"   ‚ùå Mask {i+1} embedding failed: {e}")
                import traceback
                print(f"   üìç Stack trace –¥–ª—è –º–∞—Å–∫–∏ {i+1}:")
                traceback.print_exc()

        if not vecs:
            D = getattr(self.encoder, "feat_dim", 768)
            return np.zeros((0, D), dtype=np.float32)

        V = np.stack(vecs, axis=0)  # (M,D)
        # —Ñ–∏–ª—å—Ç—Ä –º—É—Å–æ—Ä–∞: finite + –Ω–µ–Ω—É–ª–µ–≤–∞—è –Ω–æ—Ä–º–∞
        finite = np.isfinite(V).all(axis=1)
        norms = np.linalg.norm(V, axis=1)
        good = finite & (norms >= 1e-6)
        
        if not good.all():
            dropped_count = (~good).sum()
            print(f"   ‚ö†Ô∏è Dropped {dropped_count} bad mask embeddings")
            print(f"   üìç –î–ï–¢–ê–õ–ò –û–¢–ë–†–ê–°–´–í–ê–ù–ò–Ø:")
            print(f"     - –ù–µ finite: {(~finite).sum()} –º–∞—Å–æ–∫")
            print(f"     - –ù—É–ª–µ–≤–∞—è –Ω–æ—Ä–º–∞ (<1e-6): {(norms < 1e-6).sum()} –º–∞—Å–æ–∫")
            print(f"     - –ù–æ—Ä–º—ã –≤–µ–∫—Ç–æ—Ä–æ–≤: {norms}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –º–∞—Å–∫–∏ –æ—Ç–±—Ä–æ—à–µ–Ω—ã
            for i, is_good in enumerate(good):
                if not is_good:
                    print(f"     - –ú–∞—Å–∫–∞ {i+1}: finite={finite[i]}, –Ω–æ—Ä–º–∞={norms[i]:.2e}")
                    
        return V[good].astype(np.float32)

    # ---------- –ü–†–ò–ú–ï–†–´: –í–°–ï–ì–î–ê –ß–ï–†–ï–ó DINOv3 ----------
    def build_queries_multiclass(self, pos_dict, neg_list, pos_as_query_masks=False):
        """
        pos_dict: {class_name: [PIL, PIL, ...]}
        neg_list: [PIL, PIL, ...]

        return:
            q_pos: {class_name: np.ndarray (K,D)}  ‚Äî –±–µ–∑ NaN/–Ω—É–ª–µ–π
            q_neg: np.ndarray (N,D)                ‚Äî –±–µ–∑ NaN/–Ω—É–ª–µ–π
        """
        q_pos = {}
        for cls, pil_list in pos_dict.items():
            M = self._encode_pil_list(pil_list)    # (K,D)
            M = self._filter_bad(M, cls_name=cls, kind="q_pos")
            if M.shape[0] > 0:
                q_pos[cls] = M
            else:
                print(f"   ‚ö†Ô∏è –ö–ª–∞—Å—Å '{cls}' –ø—É—Å—Ç –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω")

        q_neg = self._encode_pil_list(neg_list) if neg_list else np.zeros((0, 768), dtype=np.float32)
        q_neg = self._filter_bad(q_neg, kind="q_neg")

        # –ï—Å–ª–∏ –≤—Å–µ –∫–ª–∞—Å—Å—ã –≤—ã–ø–∞–ª–∏ ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç—ã–µ, —á—Ç–æ–±—ã —Å–∫–æ—Ä–∏–Ω–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª
        if not q_pos:
            print("   ‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        return q_pos, q_neg


def build_queries_multiclass(
    pos_by_class: dict[str, list[np.ndarray] | np.ndarray],
    neg_list: list[np.ndarray] | np.ndarray | None = None,
) -> tuple[dict[str, np.ndarray], np.ndarray]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      q_pos: dict {class_name -> np.ndarray [N_c, D]} (–≤—Å–µ —Å—Ç—Ä–æ–∫–∏ L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã)
      q_neg: np.ndarray [M, D] (–º–æ–∂–µ—Ç –±—ã—Ç—å (0, D)), L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω
    """
    q_pos: dict[str, np.ndarray] = {}
    D: int | None = None

    # --- –ø–æ–∑–∏—Ç–∏–≤—ã –ø–æ –∫–ª–∞—Å—Å–∞–º
    for cls, vecs in (pos_by_class or {}).items():
        if vecs is None:
            arr = np.zeros((0, 0), dtype=np.float32)
        else:
            if isinstance(vecs, np.ndarray):
                arr = vecs
            else:
                arr = np.array(vecs, dtype=np.float32)
        if arr.size == 0:
            q_pos[cls] = np.zeros((0, 0), dtype=np.float32)
            continue
        if arr.ndim == 1:
            arr = arr[None, :]
        arr = arr.astype(np.float32, copy=False)
        arr = _l2n(arr, axis=1)
        q_pos[cls] = arr
        if D is None:
            D = arr.shape[1]

    # --- –Ω–µ–≥–∞—Ç–∏–≤—ã
    if neg_list is None:
        q_neg = np.zeros((0, D if D is not None else 0), dtype=np.float32)
    else:
        if isinstance(neg_list, np.ndarray):
            neg_arr = neg_list
        else:
            neg_arr = np.array(neg_list, dtype=np.float32)
        if neg_arr.size == 0:
            q_neg = np.zeros((0, D if D is not None else 0), dtype=np.float32)
        else:
            if neg_arr.ndim == 1:
                neg_arr = neg_arr[None, :]
            neg_arr = neg_arr.astype(np.float32, copy=False)
            neg_arr = _l2n(neg_arr, axis=1)
            q_neg = neg_arr

    # –æ—Ç–ª–∞–¥–∫–∞ –∫–∞–∫ –≤ –ª–æ–≥–∞—Ö
    try:
        total_neg = int(q_neg.shape[0])
    except Exception:
        total_neg = 0
    print(f"   DEBUG: build_queries_multiclass returning: q_pos type={type(q_pos)}, "
          f"q_neg type={type(q_neg)}, q_neg shape={getattr(q_neg, 'shape', None)}")
    return q_pos, q_neg
