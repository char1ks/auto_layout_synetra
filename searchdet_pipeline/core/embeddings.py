#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–∞—Å–æ–∫ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
- DINOv3: —á–µ—Ä–µ–∑ –æ–±—â–∏–π —ç–Ω–∫–æ–¥–µ—Ä (encode_mask / encode_image)
- DINOv2 / ResNet –ø—É—Ç—å –æ—Å—Ç–∞–≤–ª–µ–Ω –∫–∞–∫ fallback (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—Ç–∞—Ä—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏)
"""

from __future__ import annotations
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from PIL import Image
import cv2

# SearchDet (–µ—Å–ª–∏ –µ—Å—Ç—å)
try:
    from mask_withsearch import get_vector, adjust_embedding, extract_features_from_masks
    SEARCHDET_AVAILABLE = True
except Exception:
    SEARCHDET_AVAILABLE = False

# === –ù–æ–≤—ã–π —ç–Ω–∫–æ–¥–µ—Ä DINOv3 ===
try:
    from .dinov3_encoder import DinoV3Encoder
    DINOV3_OK = True
except Exception as e:
    print(f"‚ö†Ô∏è DINOv3 encoder unavailable: {e}")
    DINOV3_OK = False


class EmbeddingExtractor:
    """
    detector –¥–æ–ª–∂–µ–Ω –Ω–µ—Å—Ç–∏:
      - backbone: str (–Ω–∞–ø—Ä. dinov3_vitb16 / dinov3_convnext_base / dinov2_b / resnet101)
      - dinov3_ckpt: Optional[str]
      - device: 'cuda'|'cpu' (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
      - vit_pooling: 'cls'|'mean' (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
      - max_embedding_size: int (–º–∞—Å—à—Ç–∞–± –¥–ª—è fallback –ø—É—Ç–µ–π)
    """

    def __init__(self, detector):
        self.detector = detector
        self.backbone = getattr(detector, "backbone", "dinov2_b")
        self.device = getattr(detector, "device", "cuda")
        self.max_embedding_size = getattr(detector, "max_embedding_size", 1024)

        # --- –¥–æ–±–∞–≤–ª–µ–Ω–æ: DINOv3 encoder (–µ–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞, –∫–∞–∫ –≤ standalone —Å–∫—Ä–∏–ø—Ç–µ) ---
        self._d3 = None
        if str(self.backbone).startswith("dinov3"):
            from .dinov3_encoder import DinoV3Encoder
            self._d3 = DinoV3Encoder(
                backbone = self.backbone.replace("dinov3_", ""),  # convnext_base / vitb16 / ...
                ckpt     = getattr(detector, "dinov3_ckpt", None),
                device   = getattr(detector, "encoder_device", "cuda"),
                use_half = bool(getattr(detector, "dino_half_precision", False)),
                loader   = getattr(detector, "loader", "timm"),
                repo_dir = getattr(detector, "repo_dir", None),
            )
            print(f"üß© Using DINOv3 encoder: {self.backbone} @ {self._d3.device}, half={self._d3.use_half}")

        # –ö—ç—à —Ñ–æ—Ä–º–∞—Ç–∞: {image_id: np.ndarray} ‚Äî –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        self.cache = {}
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ query –∏–∑ –º–∞—Å–æ–∫
        self.pos_as_query_masks = bool(getattr(detector, 'pos_as_query_masks', True))
        self.min_mask_area = int(getattr(detector, 'min_mask_area', 100))

    # =========================
    # –ú–∞—Å–∫–∏
    # =========================
    def extract_mask_embeddings(self, image_np: np.ndarray, masks: List[Dict[str, Any]]) -> Tuple[np.ndarray, List[int]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (N, D) float32
          - –∏–Ω–¥–µ–∫—Å—ã –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫ (–∏—Å—Ö–æ–¥–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã)
        """
        print("üß† –≠–¢–ê–ü 2: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤...")
        valid_vecs: List[np.ndarray] = []
        valid_idx: List[int] = []

        # –ö–æ—Ä–æ—Ç–∫–æ–µ –∑–∞–º—ã–∫–∞–Ω–∏–µ –¥–ª—è DINOv3 - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º fallback –Ω–∞ SearchDet
        if self._d3 is not None:
            embs = []
            for i, m in enumerate(masks):
                seg = m.get("segmentation", None)
                if isinstance(seg, np.ndarray) and seg.dtype == bool and seg.sum() > 0:
                    try:
                        # —Å–¥–µ–ª–∞–µ–º masked-image: —Ñ–æ–Ω –∑–∞–Ω—É–ª–∏–º, —á—Ç–æ–±—ã –±—ã–ª ¬´–æ–±—ä–µ–∫—Ç¬ª
                        masked = image_np.copy()
                        masked[~seg] = 0
                        vec = self._d3.encode_image(Image.fromarray(masked))  # –≤–µ—Ä–Ω—ë—Ç L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
                        embs.append(vec.astype(np.float32))
                        valid_idx.append(i)
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è mask {i} failed: {e}")
            if embs:
                return np.vstack(embs), valid_idx
            else:
                return np.zeros((0, self._d3.model.num_features), dtype=np.float32), valid_idx

        # === Fallback: —Å—Ç–∞—Ä—ã–π SearchDet-—Ä–µ–∂–∏–º (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω –¥–ª—è dinov2/resnet) ===
        if not SEARCHDET_AVAILABLE:
            print("‚ö†Ô∏è SearchDet backend is not available ‚Üí empty embeddings")
            return np.zeros((0, 1024), dtype=np.float32), []

        mask_dicts = []
        keep = []
        for i, m in enumerate(masks):
            seg = m.get("segmentation", None)
            if isinstance(seg, np.ndarray) and seg.dtype == bool and seg.sum() > 0:
                mask_dicts.append({"segmentation": seg})
                keep.append(i)
        if not mask_dicts:
            return np.zeros((0, 1024), dtype=np.float32), []

        resnet, layer, transform = (
            getattr(self.detector, "searchdet_resnet", None),
            getattr(self.detector, "searchdet_layer", None),
            getattr(self.detector, "searchdet_transform", None),
        )
        try:
            vecs = extract_features_from_masks(image_np, mask_dicts, resnet, layer, transform)
            vecs = np.asarray(vecs, dtype=np.float32)
            # L2
            vecs /= (np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-8)
            return vecs, keep
        except Exception as e:
            print(f"‚ö†Ô∏è extract_features_from_masks failed: {e}")
            return np.zeros((0, 1024), dtype=np.float32), []
    def _extract_with_dinov3_convnext(self, image_np, mask_arrays):
        """ConvNeXt+DINOv3: —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫ —á–µ—Ä–µ–∑ bbox-crop + —Ç–æ—Ç –∂–µ preprocess, —á—Ç–æ –∏ –¥–ª—è positive."""
        import time, torch, cv2
        from PIL import Image
        t0 = time.time()

        self._ensure_dinov3_convnext()
        if self._dinov3_model is None:
            return None

        H0, W0 = image_np.shape[:2]
        scale = 1.0
        if max(H0, W0) > self.max_embedding_size:
            scale = float(self.max_embedding_size) / float(max(H0, W0))
            newW, newH = int(W0 * scale), int(H0 * scale)
            image_np = cv2.resize(image_np, (newW, newH), interpolation=cv2.INTER_LINEAR)

        embeddings = []
        ctx = float(getattr(self.detector, "mask_context", 0.08))  # 8% –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        use_half = bool(getattr(self.detector, "dino_half_precision", False))
        device = next(self._dinov3_model.parameters()).device
        model_dtype = next(self._dinov3_model.parameters()).dtype  # float32 –∏–ª–∏ float16

        with torch.no_grad():
            for i, m in enumerate(mask_arrays):
                # —Ä–µ—Å–∞–π–∑ –º–∞—Å–∫–∏ –ø–æ–¥ scale (–µ—Å–ª–∏ –±—ã–ª)
                if scale != 1.0:
                    m = cv2.resize(m.astype(np.uint8), (image_np.shape[1], image_np.shape[0]),
                                interpolation=cv2.INTER_NEAREST).astype(bool)

                ys, xs = np.where(m)
                if ys.size == 0:
                    embeddings.append(np.zeros(1024, dtype=np.float32))
                    continue

                y1, y2 = ys.min(), ys.max()
                x1, x2 = xs.min(), xs.max()

                # –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ bbox
                h, w = image_np.shape[:2]
                pad_y = int((y2 - y1 + 1) * ctx)
                pad_x = int((x2 - x1 + 1) * ctx)
                y1 = max(0, y1 - pad_y); y2 = min(h - 1, y2 + pad_y)
                x1 = max(0, x1 - pad_x); x2 = min(w - 1, x2 + pad_x)

                crop = image_np[y1:y2+1, x1:x2+1].copy()

                pil = Image.fromarray(crop)
                x = self._dinov3_preprocess(pil).unsqueeze(0)  # (1,3,224,224)
                x = x.to(device)
                # –ø—Ä–∏–≤–æ–¥–∏–º dtype –≤—Ö–æ–¥–∞ –∫ dtype –º–æ–¥–µ–ª–∏ (–≤–∞–∂–Ω–æ –¥–ª—è half)
                if model_dtype == torch.float16:
                    x = x.half()
                else:
                    x = x.float()

                z = self._dinov3_model(x)           # (1, D), num_classes=0 => pre-logits
                v = z[0].detach().cpu().float().numpy()

                # L2-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ D=1024 (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –¥—Ä—É–≥–æ–µ D)
                v = v.astype(np.float32)
                n = np.linalg.norm(v) + 1e-8
                v = v / n
                if v.shape[0] != 1024:
                    out = np.zeros(1024, dtype=np.float32)
                    take = min(1024, v.shape[0])
                    out[:take] = v[:take]
                    v = out
                embeddings.append(v)

        print(f"   ‚ö° DINOv3 ConvNeXt-B (bbox-crop): {time.time()-t0:.3f}s, N={len(embeddings)}")
        return np.stack(embeddings, axis=0).astype(np.float32)

    # =========================
    # –ü—Ä–∏–º–µ—Ä—ã (positive/negative)
    # =========================
    def build_queries(self, pos_imgs: List[Image.Image], neg_imgs: List[Image.Image]) -> Tuple[np.ndarray, np.ndarray]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (q_pos, q_neg) ‚Äî –º–∞—Ç—Ä–∏—Ü—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–∏–º–µ—Ä–æ–≤.
        –°–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–µ —Å –º–∞—Å–∫–∞–º–∏ (L2) –∏ —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º dinov3_similarity.
        """
        print(f"üîç –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ {len(pos_imgs)} positive –∏ {len(neg_imgs)} negative –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –ö–æ—Ä–æ—Ç–∫–æ–µ –∑–∞–º—ã–∫–∞–Ω–∏–µ –¥–ª—è DINOv3
        if self._d3 is not None and self.pos_as_query_masks:
            # 1) q_pos: –≤—Å–µ –≤–∞–ª–∏–¥–Ω—ã–µ –º–∞—Å–∫–∏ –∏–∑ positive
            pos_vecs = []
            for i, pil in enumerate(pos_imgs or []):
                img_np = np.array(pil)
                masks = self._gen_masks_for_image(img_np)
                for md in masks:
                    m = md.get('segmentation', None)
                    if isinstance(m, np.ndarray) and m.dtype == bool and m.sum() >= self.min_mask_area:
                        pos_vecs.append(self._encode_mask_d3(img_np, m))
            q_pos = np.stack(pos_vecs, 0) if pos_vecs else np.zeros((0, 1024), np.float32)

            # 2) q_neg: –ø–æ –∂–µ–ª–∞–Ω–∏—é ‚Äî –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ (–∏–ª–∏ –ø—É—Å—Ç–æ, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å)
            neg_vecs = []
            for i, pil in enumerate(neg_imgs or []):
                img_np = np.array(pil)
                masks = self._gen_masks_for_image(img_np)
                for md in masks:
                    m = md.get('segmentation', None)
                    if isinstance(m, np.ndarray) and m.dtype == bool and m.sum() >= self.min_mask_area:
                        neg_vecs.append(self._encode_mask_d3(img_np, m))
            q_neg = np.stack(neg_vecs, 0) if neg_vecs else np.zeros((0, 1024), np.float32)

            print(f"   üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ positive-–º–∞—Å–æ–∫: {q_pos.shape[0]}, negative-–º–∞—Å–æ–∫: {q_neg.shape[0]}")
            return q_pos.astype(np.float32), q_neg.astype(np.float32)
        
        elif self._d3 is not None:
            def _vec(img):
                v = self._d3.encode_image(img)
                n = np.linalg.norm(v); v = v / (n + 1e-8)
                if v.shape[0] != 1024:
                    out = np.zeros(1024, np.float32); out[:min(1024, v.shape[0])] = v[:min(1024, v.shape[0])]
                    v = out
                return v.astype(np.float32)

            pos = np.stack([_vec(im) for im in pos_imgs], 0) if pos_imgs else np.zeros((0,1024), np.float32)
            neg = np.stack([_vec(im) for im in neg_imgs], 0) if neg_imgs else np.zeros((0,1024), np.float32)
            print(f"   üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ positive: {pos.shape[0]}, negative: {neg.shape[0]}")
            return pos, neg

        # Fallback: —Å—Ç–∞—Ä—ã–π –ø—É—Ç—å (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
        if not SEARCHDET_AVAILABLE:
            return np.zeros((0, 1024), dtype=np.float32), np.zeros((0, 1024), dtype=np.float32)

        pos_vecs, neg_vecs = [], []
        resnet, layer, transform = (
            getattr(self.detector, "searchdet_resnet", None),
            getattr(self.detector, "searchdet_layer", None),
            getattr(self.detector, "searchdet_transform", None),
        )
        def _one(img: Image.Image) -> Optional[np.ndarray]:
            try:
                v = get_vector(img, resnet, layer, transform)
                v = np.asarray(v, dtype=np.float32).reshape(-1)
                v /= (np.linalg.norm(v) + 1e-8)
                return v
            except Exception:
                return None

        for im in (pos_imgs or []):
            v = _one(im)
            if v is not None:
                pos_vecs.append(v)
        for im in (neg_imgs or []):
            v = _one(im)
            if v is not None:
                neg_vecs.append(v)

        D = pos_vecs[0].shape[0] if pos_vecs else (neg_vecs[0].shape[0] if neg_vecs else 1024)
        Qp = np.stack(pos_vecs, axis=0) if pos_vecs else np.zeros((0, D), dtype=np.float32)
        Qn = np.stack(neg_vecs, axis=0) if neg_vecs else np.zeros((0, D), dtype=np.float32)
        return Qp, Qn

    # –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å: {cls: [PIL,...]}, neg:[PIL,...]
    def build_queries_multiclass(self, pos_by_class: Dict[str, List[Image.Image]], neg_imgs: List[Image.Image]):
        # –ö–æ—Ä–æ—Ç–∫–æ–µ –∑–∞–º—ã–∫–∞–Ω–∏–µ –¥–ª—è DINOv3
        if self._d3 is not None:
            def _vec(img):
                v = self._d3.encode_image(img)
                n = np.linalg.norm(v); v = v / (n + 1e-8)
                if v.shape[0] != 1024:
                    out = np.zeros(1024, np.float32); out[:min(1024, v.shape[0])] = v[:min(1024, v.shape[0])]
                    v = out
                return v.astype(np.float32)

            # neg
            neg = np.stack([_vec(im) for im in neg_imgs], 0) if neg_imgs else np.zeros((0,1024), np.float32)
            
            # pos by class
            class_pos = {}
            for cls, imgs in (pos_by_class or {}).items():
                Q = np.stack([_vec(im) for im in imgs], 0) if imgs else np.zeros((0,1024), np.float32)
                class_pos[cls] = Q

            print(f"   üìä Negative –≤—Å–µ–≥–æ: {neg.shape[0]}")
            for c, Q in class_pos.items():
                print(f"   üìä –ö–ª–∞—Å—Å '{c}': {Q.shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤")
            return class_pos, neg

        # Fallback —Å—Ç–∞—Ä–æ–≥–æ –ø—É—Ç–∏:
        class_pos = {}
        for cls, imgs in (pos_by_class or {}).items():
            vecs = []
            for im in (imgs or []):
                try:
                    v = get_vector(im, getattr(self.detector, "searchdet_resnet", None),
                                   getattr(self.detector, "searchdet_layer", None),
                                   getattr(self.detector, "searchdet_transform", None))
                    v = np.asarray(v, dtype=np.float32).reshape(-1)
                    v /= (np.linalg.norm(v) + 1e-8)
                    vecs.append(v)
                except Exception:
                    pass
            D = vecs[0].shape[0] if vecs else 1024
            class_pos[cls] = (np.stack(vecs, axis=0) if vecs else np.zeros((0, D), dtype=np.float32))
        neg_vecs = []
        for im in (neg_imgs or []):
            try:
                v = get_vector(im, getattr(self.detector, "searchdet_resnet", None),
                               getattr(self.detector, "searchdet_layer", None),
                               getattr(self.detector, "searchdet_transform", None))
                v = np.asarray(v, dtype=np.float32).reshape(-1)
                v /= (np.linalg.norm(v) + 1e-8)
                neg_vecs.append(v)
            except Exception:
                pass
        Dn = neg_vecs[0].shape[0] if neg_vecs else 1024
        Qn = (np.stack(neg_vecs, axis=0) if neg_vecs else np.zeros((0, Dn), dtype=np.float32))
        return class_pos, Qn

    # =========================
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    # =========================
    
    def _encode_mask_d3(self, image_np: np.ndarray, mask_bool: np.ndarray) -> np.ndarray:
        """–ó–∞–Ω—É–ª—è–µ–º —Ñ–æ–Ω –∏ —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ DINOv3."""
        masked = image_np.copy()
        masked[~mask_bool] = 0
        v = self._d3.encode_image(masked)  # –≤–Ω—É—Ç—Ä–∏ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π device/dtype
        # L2 –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
        n = np.linalg.norm(v)
        if n > 1e-8:
            v = v / n
        return v.astype(np.float32)
    
    def _gen_masks_for_image(self, image_np: np.ndarray):
        """–í—ã–∑—ã–≤–∞–µ–º —Ç–æ—Ç –∂–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∞—Å–æ–∫, —á—Ç–æ –∏ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ, —Å —Ç–≤–æ–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏."""
        if hasattr(self.detector, "generate_masks"):
            return self.detector.generate_masks(image_np)  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å [{'segmentation': bool np.ndarray, ...}, ...]
        # –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –≥—Ä—É–±—ã–π fallback: –æ–¥–Ω–∞ ¬´–≤—Å—è –∫–∞—Ä—Ç–∏–Ω–∫–∞¬ª
        h,w = image_np.shape[:2]
        return [{'segmentation': np.ones((h,w), dtype=bool)}]
