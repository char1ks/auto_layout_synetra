#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–∞—Å–æ–∫ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ SearchDet.
"""

import numpy as np
import cv2
from PIL import Image
import torch
import torchvision.transforms as transforms
import os
try:
    from mask_withsearch import get_vector, adjust_embedding, extract_features_from_masks
    SEARCHDET_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è SearchDet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    SEARCHDET_AVAILABLE = False

import torch.nn as nn
import time


class EmbeddingExtractor:
    def __init__(self, detector):
        self.detector = detector
        self.backbone = getattr(detector, 'backbone', 'dinov2_b')
        # –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DINO –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        self._dino_model = None
        self._dino_preprocess = None
        # üöÄ –ö—ç—à –¥–ª—è DINO forward pass
        self._dino_cache = {}  # {image_hash: (patch_tokens, grid_size)}
        # üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.max_embedding_size = getattr(detector, 'max_embedding_size', 1024)
        # üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª–æ–≤–∏–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è DINO
        self.dino_half_precision = getattr(detector, 'dino_half_precision', False)
        # DINOv3 ConvNeXt-B –ø–æ–ª—è
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        self._dinov3_model = getattr(detector, 'dinov3_model', None)
        self._dinov3_preprocess = None
        self.dinov3_checkpoint_path = getattr(detector, 'dinov3_checkpoint_path', None)
        
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è DINOv3 (CPU/GPU)
        self._dinov3_device = getattr(detector, 'dinov3_device', None)
    
    def extract_mask_embeddings(self, image_np, masks):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –º–∞—Å–æ–∫."""
        print("üß† –≠–¢–ê–ü 2: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤...")
        print(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(masks)} –º–∞—Å–æ–∫...")
        
        if not SEARCHDET_AVAILABLE:
            print("‚ö†Ô∏è SearchDet –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
            return np.zeros((0, 1024), dtype=np.float32), []
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PIL
        pil_image = Image.fromarray(image_np)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–∞—Å–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ boolean numpy array —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        mask_arrays = []
        valid_indices = []
        min_mask_area = 100  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –º–∞—Å–∫–∏ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        
        for i, mask_dict in enumerate(masks):
            mask = mask_dict["segmentation"]
            if isinstance(mask, np.ndarray) and mask.dtype == bool:
                # üöÄ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä—É —Å—Ä–∞–∑—É –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ
                mask_area = np.sum(mask)
                if mask_area >= min_mask_area:
                    mask_arrays.append(mask)
                    valid_indices.append(i)
            else:
                print(f"   ‚ö†Ô∏è –ú–∞—Å–∫–∞ {i} –∏–º–µ–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø: {type(mask)}")
        
        if len(mask_arrays) < len(masks):
            print(f"   üîç –ü—Ä–µ–¥—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞—Å–æ–∫: {len(masks)} ‚Üí {len(mask_arrays)} (—É–¥–∞–ª–µ–Ω–æ {len(masks) - len(mask_arrays)} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö/–º–∞–ª–µ–Ω—å–∫–∏—Ö –º–∞—Å–æ–∫)")
        
        if not mask_arrays:
            print("   ‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
            return np.zeros((0, 1024), dtype=np.float32), []
        
        print(f"üöÄ –ë–´–°–¢–†–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(mask_arrays)} –º–∞—Å–æ–∫ (Masked Pooling)...")
        
        try:
            embeddings = self._extract_fast(image_np, mask_arrays)
            if embeddings is not None:
                print(f"‚ö° –ë–´–°–¢–†–û: {len(mask_arrays)} –º–∞—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
                # --- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ (N, D) float32 ---
                embeddings = np.asarray(embeddings)
                if embeddings.ndim == 1:
                    embeddings = embeddings.reshape(1, -1)
                elif embeddings.ndim > 2:
                    embeddings = embeddings.reshape(embeddings.shape[0], -1)
                embeddings = embeddings.astype(np.float32)
                return embeddings, valid_indices
        except Exception as e:
            print(f"‚ö†Ô∏è –ë—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π")
        
        print(f"üß† –ú–ï–î–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(mask_arrays)} –º–∞—Å–æ–∫...")
        try:
            embeddings = self._extract_slow(pil_image, mask_arrays)
            if embeddings is not None:
                print(f"‚úÖ –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(mask_arrays)} –º–∞—Å–æ–∫")
                embeddings = np.asarray(embeddings)
                if embeddings.ndim == 1:
                    embeddings = embeddings.reshape(1, -1)
                elif embeddings.ndim > 2:
                    embeddings = embeddings.reshape(embeddings.shape[0], -1)
                embeddings = embeddings.astype(np.float32)
                return embeddings, valid_indices
        except Exception as e:
            print(f"‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Ç–∞–∫–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
        return np.zeros((0, 1024), dtype=np.float32), []
    
    def _extract_fast(self, image_np, mask_arrays):
        import time
        import os
        # === DINOv3 ConvNeXt-B: —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –≤–µ—Ç–∫–∞ ===
        if self.backbone.startswith('dinov3'):
            return self._extract_with_dinov3_convnext(image_np, mask_arrays)
        
        if self.backbone.startswith('dinov2'):
            return self._extract_with_dino(image_np, mask_arrays)
            
        extract_start = time.time()
        print(f"üöÄ –ë–´–°–¢–†–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(mask_arrays)} –º–∞—Å–æ–∫ (Masked Pooling)...")
        
        resnet, layer, transform, sam = (
            self.detector.searchdet_resnet,
            self.detector.searchdet_layer, 
            self.detector.searchdet_transform,
            self.detector.searchdet_sam
        )
        
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º {layer} –¥–ª—è –±–æ–ª—å—à–µ–≥–æ feature map")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ tuple –∏–∑ –º–æ–¥–µ–ª–µ–π
        if isinstance(resnet, tuple) and len(resnet) >= 2:
            model = resnet[0]  # backbone
            device = resnet[1] if len(resnet) > 1 else 'cuda'
        else:
            model = resnet
            device = 'cuda'
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º mask_arrays –≤ —Ñ–æ—Ä–º–∞—Ç, –æ–∂–∏–¥–∞–µ–º—ã–π extract_features_from_masks
        # –§—É–Ω–∫—Ü–∏—è –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–æ–º 'segmentation'
        mask_dicts = []
        for mask_array in mask_arrays:
            mask_dicts.append({'segmentation': mask_array})
        
        # üöÄ –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if model is not None and layer is not None:
                embeddings = extract_features_from_masks(image_np, mask_dicts, model, layer, transform)
                if isinstance(embeddings, np.ndarray) and embeddings.ndim == 2 and embeddings.shape[0] == len(mask_arrays):
                    extract_time = time.time() - extract_start
                    old_time_estimate = len(mask_arrays) * 0.1  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Å—Ç–∞—Ä–æ–≥–æ –º–µ—Ç–æ–¥–∞
                    speedup = old_time_estimate / extract_time if extract_time > 0 else 1
                    print(f"   ‚ö° –ë–´–°–¢–†–û: {extract_time:.3f} —Å–µ–∫ ({extract_time/len(mask_arrays)*1000:.1f} –º—Å/–º–∞—Å–∫–∞) - —É—Å–∫–æ—Ä–µ–Ω–∏–µ ~{speedup:.1f}x")
                    return embeddings
        except Exception as e:
            print(f"   ‚ö†Ô∏è –ë—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        
        # Fallback: –ø—Ä–æ–±—É–µ–º –±–µ–∑ transform
        try:
            if model is not None and layer is not None:
                embeddings = extract_features_from_masks(image_np, mask_dicts, model, layer, None)
                if isinstance(embeddings, np.ndarray) and embeddings.ndim == 2:
                    extract_time = time.time() - extract_start
                    print(f"   ‚ö° –ë–´–°–¢–†–û (–±–µ–∑ transform): {extract_time:.3f} —Å–µ–∫")
                    return embeddings
        except Exception as e:
            print(f"   ‚ö†Ô∏è –ë—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –±–µ–∑ transform –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        
        return None
    
    def _extract_slow(self, pil_image, mask_arrays):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–µ–¥–ª–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."""
        import time
        import cv2
        
        extract_start = time.time()
        print(f"üêå –ú–ï–î–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(mask_arrays)} –º–∞—Å–æ–∫...")
        
        if self.backbone.startswith('dinov3'):
            return self._extract_with_dinov3_convnext(np.array(pil_image), mask_arrays)
        
        if self.backbone.startswith('dinov2'):
            return self._extract_with_dino(np.array(pil_image), mask_arrays)
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ SearchDet
        resnet, layer, transform, sam = (
            self.detector.searchdet_resnet,
            self.detector.searchdet_layer, 
            self.detector.searchdet_transform,
            self.detector.searchdet_sam
        )
        
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º {layer} –¥–ª—è –±–æ–ª—å—à–µ–≥–æ feature map")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ tuple –∏–∑ –º–æ–¥–µ–ª–µ–π
        if isinstance(resnet, tuple) and len(resnet) >= 2:
            model = resnet[0]  # backbone
            device = resnet[1] if len(resnet) > 1 else 'cuda'
        else:
            model = resnet
            device = 'cuda'
        
        # üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        original_image = np.array(pil_image)
        h, w = original_image.shape[:2]
        
        if max(h, w) > self.max_embedding_size:
            scale = self.max_embedding_size / max(h, w)
            new_h, new_w = int(h * scale), int(w * scale)
            scaled_image = cv2.resize(original_image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            print(f"   üìè –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {w}x{h} ‚Üí {new_w}x{new_h} (scale={scale:.3f}, max_size={self.max_embedding_size})")
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –º–∞—Å–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ
            scaled_mask_arrays = []
            for mask_array in mask_arrays:
                scaled_mask = cv2.resize(mask_array.astype(np.uint8), (new_w, new_h), interpolation=cv2.INTER_NEAREST)
                scaled_mask_arrays.append(scaled_mask.astype(bool))
            mask_arrays = scaled_mask_arrays
            pil_image = Image.fromarray(scaled_image)
        
        # –ü—Ä–æ–±—É–µ–º –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ extract_features_from_masks_slow
        try:
            mask_dicts = []
            for mask_array in mask_arrays:
                mask_dicts.append({'segmentation': mask_array})
            
            image_np = np.array(pil_image)
            
            from mask_withsearch import extract_features_from_masks_slow
            embeddings = extract_features_from_masks_slow(image_np, mask_dicts, model, layer, transform)
            
            if isinstance(embeddings, np.ndarray) and embeddings.ndim == 2:
                extract_time = time.time() - extract_start
                print(f"   üêå –ú–ï–î–õ–ï–ù–ù–û (batch): {extract_time:.3f} —Å–µ–∫ ({extract_time/len(mask_arrays)*1000:.1f} –º—Å/–º–∞—Å–∫–∞)")
                return embeddings
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞: {e}")
        
        # Fallback: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Å–∫–∏ –ø–æ –æ–¥–Ω–æ–π
        print(f"   üîÑ Fallback: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∞—Å–∫–∏ –ø–æ –æ–¥–Ω–æ–π...")
        embeddings = []
        for i, mask in enumerate(mask_arrays):
            try:
                image_np = np.array(pil_image)
                mask_image = np.zeros_like(image_np)
                mask_image[mask] = image_np[mask]
                
                mask_pil = Image.fromarray(mask_image)
                
                vec = get_vector(mask_pil, model, layer, transform)
                if hasattr(vec, 'numpy'):
                    embeddings.append(vec.numpy())
                else:
                    embeddings.append(vec)
                    
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å –º–∞—Å–∫–æ–π {i}: {e}")
                embeddings.append(np.random.rand(1024).astype(np.float32))
        
        if embeddings:
            embeddings_array = np.array(embeddings)
            norms = np.linalg.norm(embeddings_array, axis=1, keepdims=True)
            embeddings_array = embeddings_array / (norms + 1e-8)
            extract_time = time.time() - extract_start
            print(f"   üêå –ú–ï–î–õ–ï–ù–ù–û (–ø–æ –æ–¥–Ω–æ–π): {extract_time:.3f} —Å–µ–∫ ({extract_time/len(mask_arrays)*1000:.1f} –º—Å/–º–∞—Å–∫–∞)")
            return embeddings_array
        
        return None
    
    def build_queries(self, pos_imgs, neg_imgs):
        """–°—Ç—Ä–æ–∏—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ positive/negative –ø—Ä–∏–º–µ—Ä–æ–≤."""
        print(f"üîç –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ {len(pos_imgs)} positive –∏ {len(neg_imgs)} negative –ø—Ä–∏–º–µ—Ä–æ–≤")
        if self.backbone.startswith('dinov2'):
            # DINO –ø—É—Ç—å: –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –±–µ–∑ –º–∞—Å–æ–∫
            pos_list = []
            for i, img in enumerate(pos_imgs):
                try:
                    vec = self._get_dino_global(np.array(img))
                    if vec is not None:
                        pos_list.append(vec)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å positive {i}: {e}")
            neg_list = []
            for i, img in enumerate(neg_imgs):
                try:
                    vec = self._get_dino_global(np.array(img))
                    if vec is not None:
                        neg_list.append(vec)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å negative {i}: {e}")
            q_pos = np.array(pos_list) if pos_list else np.array([]).reshape(0, 1024)
            q_neg = np.array(neg_list) if neg_list else np.array([]).reshape(0, 1024)
            # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if q_pos.shape[0] > 0:
                q_pos = q_pos / (np.linalg.norm(q_pos, axis=1, keepdims=True) + 1e-8)
            if q_neg.shape[0] > 0:
                q_neg = q_neg / (np.linalg.norm(q_neg, axis=1, keepdims=True) + 1e-8)
            print(f"   üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ positive: {q_pos.shape[0]}, negative: {q_neg.shape[0]}")
            return q_pos.astype(np.float32), q_neg.astype(np.float32)

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ SearchDet
        resnet, layer, transform, sam = (
            self.detector.searchdet_resnet,
            self.detector.searchdet_layer, 
            self.detector.searchdet_transform,
            self.detector.searchdet_sam
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ tuple –∏–∑ –º–æ–¥–µ–ª–µ–π
        if isinstance(resnet, tuple) and len(resnet) >= 2:
            model = resnet[0]  # backbone
            device = resnet[1] if len(resnet) > 1 else 'cuda'
        else:
            model = resnet
            device = 'cuda'
        
        # Positive —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        pos_list = []
        for i, img in enumerate(pos_imgs):
            try:
                vec = self._get_image_embedding(img, model, layer, transform)
                if vec is not None:
                    pos_list.append(vec)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å positive {i}: {e}")
        
        # Negative —ç–º–±–µ–¥–¥–∏–Ω–≥–∏  
        neg_list = []
        for i, img in enumerate(neg_imgs):
            try:
                vec = self._get_image_embedding(img, model, layer, transform)
                if vec is not None:
                    neg_list.append(vec)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å negative {i}: {e}")
        
        q_pos = np.array(pos_list) if pos_list else np.array([]).reshape(0, 1024)
        q_neg = np.array(neg_list) if neg_list else np.array([]).reshape(0, 1024)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ positive —Å —É—á—ë—Ç–æ–º negative (–∫–∞–∫ –≤ hybrid)
        if q_pos.shape[0] > 0 and q_neg.shape[0] > 0:
            try:
                adjusted = np.stack([adjust_embedding(q, q_pos, q_neg) for q in q_pos], axis=0).astype(np.float32)
                q_pos = adjusted
            except Exception as e:
                print(f"   ‚ö†Ô∏è adjust_embedding error, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ: {e}")
        
        # L2-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if q_pos.shape[0] > 0:
            q_pos = q_pos / (np.linalg.norm(q_pos, axis=1, keepdims=True) + 1e-8)
        if q_neg.shape[0] > 0:
            q_neg = q_neg / (np.linalg.norm(q_neg, axis=1, keepdims=True) + 1e-8)
        
        print(f"   üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ positive: {q_pos.shape[0]}, negative: {q_neg.shape[0]}")
        return q_pos.astype(np.float32), q_neg.astype(np.float32)
    
    def _get_image_embedding(self, pil_image, model, layer, transform):
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        if not SEARCHDET_AVAILABLE:
            # –ó–∞–≥–ª—É—à–∫–∞
            return np.random.rand(1024).astype(np.float32)
        
        if self.backbone.startswith('dinov3'):
            return self._get_dinov3_global(np.array(pil_image))
        
        if self.backbone.startswith('dinov2'):
            return self._get_dino_global(np.array(pil_image))

        try:
            vec = get_vector(pil_image, model, layer, transform)
            if isinstance(vec, np.ndarray):
                return vec
            
            # –ï—Å–ª–∏ —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä PyTorch
            if hasattr(vec, 'numpy'):
                return vec.numpy()
                
            return None
        except Exception as e:
            print(f"   ‚ö†Ô∏è get_vector failed: {e}")
            
            try:
                # Fallback - —Å–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
                return np.random.rand(1024).astype(np.float32)
            except:
                return None

    def _ensure_dino(self):
        if self._dino_model is not None:
            return
        try:
            import timm
            import torchvision.transforms as T
            from torchvision.transforms import InterpolationMode
            
            name_map = {
                'dinov2_s': 'vit_small_patch14_dinov2.lvd142m',
                'dinov2_b': 'vit_base_patch14_dinov2.lvd142m',
                'dinov2_l': 'vit_large_patch14_dinov2.lvd142m',
                'dinov2_g': 'vit_giant_patch14_dinov2.lvd142m',
            }
            model_name = name_map.get(self.backbone, 'vit_base_patch14_dinov2.lvd142m')
            self._dino_model = timm.create_model(model_name, pretrained=True)
            self._dino_model.eval()
            
            # üöÄ –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
            if self.dino_half_precision:
                self._dino_model = self._dino_model.half()
                print(f"   ‚ö° DINO –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ float16 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
            
            data_config = self._dino_model.default_cfg
            self.dino_img_size = data_config['input_size'][-1]
            
            try:
                patch_size = self._dino_model.patch_embed.patch_size[0]
                self.dino_grid_size = (self.dino_img_size // patch_size, self.dino_img_size // patch_size)
            except Exception:
                self.dino_grid_size = (37, 37)
            class SquarePad:
                def __call__(self, image):
                    w, h = image.size
                    max_wh = np.max([w, h])
                    hp = (max_wh - w) // 2
                    vp = (max_wh - h) // 2
                    padding = (hp, vp, max_wh - w - hp, max_wh - h - vp)
                    return T.functional.pad(image, padding, 0, 'constant')

            self._dino_preprocess = T.Compose([
                SquarePad(),
                T.Resize(self.dino_img_size, interpolation=InterpolationMode.BICUBIC, antialias=True),
                T.CenterCrop(self.dino_img_size),
                T.ToTensor(),
                T.Normalize(mean=data_config['mean'], std=data_config['std']),
            ])
            
            print(f"üß© DINO backbone={self.backbone}, img_size={self.dino_img_size}, grid={self.dino_grid_size}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å DINOv2: {e}")
            self._dino_model = None

    def _get_dino_global(self, image_np: np.ndarray):
        self._ensure_dino()
        if self._dino_model is None:
            return np.random.rand(1024).astype(np.float32)
        import torch
        with torch.no_grad():
            pil = Image.fromarray(image_np)
            x = self._dino_preprocess(pil).unsqueeze(0)
            
            # üöÄ –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∫ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.dino_half_precision:
                x = x.half()
            
            feats = self._dino_model.forward_features(x)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞: –º–æ–∂–µ—Ç –±—ã—Ç—å dict –∏–ª–∏ tensor
            if isinstance(feats, dict):
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: CLS —Ç–æ–∫–µ–Ω, –µ—Å–ª–∏ –µ—Å—Ç—å
                if 'x_norm_clstoken' in feats:
                    vec = feats['x_norm_clstoken'][0]
                # Fallback: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–∞—Ç—á–∞–º
                elif 'x_norm_patchtokens' in feats:
                    vec = feats['x_norm_patchtokens'][0].mean(dim=0)
                else: # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç dict
                    vec = next(iter(feats.values()))[0].mean(dim=0)
            elif torch.is_tensor(feats):
                # –ï—Å–ª–∏ feats - —Ç–µ–Ω–∑–æ—Ä, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º (B, N, D)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º CLS —Ç–æ–∫–µ–Ω (–ø–µ—Ä–≤—ã–π) –∫–∞–∫ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä
                if feats.ndim == 3 and feats.shape[1] > 0:
                    vec = feats[0, 0]
                # Fallback: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º/–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É
                else:
                    vec = feats[0].mean(dim=0)
            else: # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø
                return np.random.rand(1024).astype(np.float32)

            vec = vec.detach().cpu().float().numpy().squeeze()
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ 1024 –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if vec.shape[0] != 1024:
                out = np.zeros(1024, dtype=np.float32)
                take = min(1024, vec.shape[0])
                out[:take] = vec[:take]
                vec = out
                
            # L2 norm
            vec_norm = np.linalg.norm(vec)
            if vec_norm > 1e-8:
                vec = vec / vec_norm
            return vec.astype(np.float32)

    def _extract_with_dino(self, image_np, valid_masks):
        import torch.nn.functional as F
        
        self._ensure_dino()
        if self._dino_model is None:
            return np.zeros((0, 1024), dtype=np.float32)

        image_pil = Image.fromarray(image_np)
        image_hash = hash(image_pil.tobytes())

        # === –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ===
        if image_hash in self._dino_cache:
            patch_tokens, grid_size = self._dino_cache[image_hash]
            gh, gw = grid_size
        else:
            with torch.no_grad():
                # üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π forward_features
                features_dict = self._dino_model.forward_features(self._dino_preprocess(image_pil).unsqueeze(0).to(self._dino_device))
                patch_tokens = features_dict['x_norm_patchtokens'].squeeze(0) # (T, D)
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—Ç—á-—Ç–æ–∫–µ–Ω—ã –ø–µ—Ä–µ–¥ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                if isinstance(patch_tokens, torch.Tensor):
                    patch_tokens = F.normalize(patch_tokens.float(), p=2, dim=-1)
                else:
                    patch_tokens = torch.from_numpy(patch_tokens).float()
                    patch_tokens = F.normalize(patch_tokens, p=2, dim=-1)

                gh, gw = features_dict['hw']
                self.dino_grid_size = (gh, gw)
                self._dino_cache[image_hash] = (patch_tokens.clone(), self.dino_grid_size)

        # === –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–æ–∫ ===
        mask_tensors = [torch.from_numpy(m.astype(np.float32)).unsqueeze(0).unsqueeze(0) for m in valid_masks]
        batch_masks = torch.cat(mask_tensors, dim=0).to(self._dino_device)
        
        # –ë–´–õ–û: 'bilinear', —á—Ç–æ —Ä–∞–∑–º—ã–≤–∞–µ—Ç –º–∞—Å–∫—É. –°–¢–ê–õ–û: 'nearest'
        resized_batch = F.interpolate(batch_masks, size=(gh, gw), mode='nearest')
        mask_bool = (resized_batch.squeeze(1) > 0.5) # [N, gh, gw]

        embeddings = []
        for batch_idx in range(len(valid_masks)):
            
            foreground_indices = torch.where(mask_bool[batch_idx].flatten())[0]
            if len(foreground_indices) == 0:
                # –ó–∞—â–∏—Ç–∞ –Ω–∞ —Å–ª—É—á–∞–π —Ç–æ–Ω–∫–∏—Ö –º–∞—Å–æ–∫ ‚Äî –±–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–∏–∫—Å–µ–ª—è
                flat = resized_batch.squeeze(1)[batch_idx].flatten()
                foreground_indices = torch.tensor([int(torch.argmax(flat))], device=flat.device)

            if len(foreground_indices) > 0:
                mask_patch_tokens = patch_tokens[foreground_indices]
                embedding = mask_patch_tokens.mean(dim=0)
            else:
                # Fallback: –µ—Å–ª–∏ –º–∞—Å–∫–∞ –ø—É—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CLS —Ç–æ–∫–µ–Ω (–≥–ª–æ–±–∞–ª—å–Ω—ã–π)
                embedding = patch_tokens.mean(dim=0) # –£—Å—Ä–µ–¥–Ω—è–µ–º –≤—Å–µ –ø–∞—Ç—á–∏ –∫–∞–∫ fallback

            # –§–∏–Ω–∞–ª—å–Ω–∞—è L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            embedding = F.normalize(embedding.float(), p=2, dim=0)
            embeddings.append(embedding.cpu().numpy())

        return np.array(embeddings).astype(np.float32)

    # Modify negative embeddings to use central region instead of global average
    def _get_dinov3_central(self, image_np):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        if self._dinov3_model is None:
            raise ValueError("DINOv3 –º–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ PIL –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        if isinstance(image_np, np.ndarray):
            image_pil = Image.fromarray(image_np)
        else:
            raise TypeError(f"Unexpected type {type(image_np)}")
    
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        x = self._dinov3_preprocess(image_pil).unsqueeze(0).to(self._dinov3_device)
    
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π
        feats = self._dinov3_model.forward_features(x)
    
        # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω
        h, w = feats.shape[-2:]
        center_h, center_w = h // 2, w // 2
        central_feats = feats[:, :, center_h - 1:center_h + 2, center_w - 1:center_w + 2]
    
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
        central_embedding = central_feats.mean(dim=[-2, -1])
        return central_embedding.py()

    # Update build_queries_multiclass to use central embedding for negatives
    def build_queries_multiclass(self, pos_by_class, neg_imgs):
        if str(self.backbone).startswith('dinov3'):
            self._ensure_dinov3_convnext()
            D = 1024

            # NEGATIVE
            neg_list = []
            for img in (neg_imgs or []):
                v = self._get_dinov3_central(np.array(img))  # Use central embedding
                v = v.astype(np.float32); v /= (np.linalg.norm(v)+1e-8)
                neg_list.append(v)
            q_neg = np.stack(neg_list, axis=0) if neg_list else np.zeros((0,D), np.float32)

            # POSITIVE
            class_pos = {}
            for cls, imgs in (pos_by_class or {}).items():
                vecs = []
                for img in (imgs or []):
                    v = self._get_dinov3_global(np.array(img))
                    v = v.astype(np.float32); v /= (np.linalg.norm(v)+1e-8)
                    vecs.append(v)
                Q = np.stack(vecs, axis=0) if vecs else np.zeros((0,D), np.float32)
                class_pos[cls] = Q

            # --- –§–∏–ª—å—Ç—Ä –Ω–µ–≥–∞—Ç–∏–≤–æ–≤, –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤—ã ---
            pos_stack = []
            for cls2, Q2 in (class_pos or {}).items():
                if Q2 is not None and Q2.size:
                    pos_stack.append(Q2.astype(np.float32))
            if len(pos_stack):
                import os
                P = np.vstack(pos_stack)
                P /= (np.linalg.norm(P, axis=1, keepdims=True) + 1e-8)
                if q_neg.shape[0] > 0:
                    qn = q_neg.astype(np.float32)
                    qn /= (np.linalg.norm(qn, axis=1, keepdims=True) + 1e-8)
                    sims_np = qn @ P.T
                    thr = float(os.getenv('SEARCHDET_NEG_FILTER_THR', '0.60'))
                    keep = (np.max(sims_np, axis=1) <= thr)
                    dropped = int((~keep).sum())
                    if dropped:
                        print(f"   üßπ –£–±—Ä–∞–Ω–æ {dropped} –Ω–µ–≥–∞—Ç–∏–≤–æ–≤ (—Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤—ã; thr={thr:.2f})")
                    q_neg = q_neg[keep]

            return class_pos, q_neg
        
        if str(self.backbone).startswith('dinov2'):
            self._ensure_dino()
            D = 1024

            neg_list = []
            for i, img in enumerate(neg_imgs or []):
                try:
                    v = self._get_dino_global(np.array(img))
                    v = np.asarray(v, dtype=np.float32).reshape(-1)
                    v /= (np.linalg.norm(v) + 1e-8)
                    neg_list.append(v.copy())
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å negative {i}: {e}")
            q_neg = np.stack(neg_list, axis=0) if neg_list else np.zeros((0, D), dtype=np.float32)
            class_pos = {}
            if pos_by_class is None:
                pos_by_class = {}
            for cls, imgs in (pos_by_class or {}).items():
                vecs = []
                for i, img in enumerate(imgs or []):
                    try:
                        v = self._get_dino_global(np.array(img))
                        v = np.asarray(v, dtype=np.float32).reshape(-1)
                        v /= (np.linalg.norm(v) + 1e-8)
                        vecs.append(v.copy())
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å positive '{cls}' #{i}: {e}")
                Q = np.stack(vecs, axis=0) if vecs else np.zeros((0, D), dtype=np.float32)
                class_pos[cls] = Q.astype(np.float32)
                print(f"   üìä –ö–ª–∞—Å—Å '{cls}': {Q.shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤")
            print(f"   üìä Negative –≤—Å–µ–≥–æ: {q_neg.shape[0]}")
            return class_pos, q_neg.astype(np.float32)
        resnet, layer, transform, sam = (
            self.detector.searchdet_resnet,
            self.detector.searchdet_layer,
            self.detector.searchdet_transform,
            self.detector.searchdet_sam
        )

        if isinstance(resnet, tuple) and len(resnet) >= 2:
            model = resnet[0]
            device = resnet[1] if len(resnet) > 1 else 'cuda'
        else:
            model = resnet
            device = 'cuda'

        # –°–Ω–∞—á–∞–ª–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –°–õ–£–ß–ê–ô–ù–´–ï –û–ë–õ–ê–°–¢–ò –≤–º–µ—Å—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        neg_list = []
        embedding_dim = None
        for i, img in enumerate(neg_imgs or []):
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –∏–∑ negative –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                neg_regions = self._extract_random_regions_from_image(img, num_regions=5)
                for region_vec in neg_regions:
                    if region_vec is None:
                        continue
                    vec = np.asarray(region_vec, dtype=np.float32).reshape(-1)
                    if embedding_dim is None: embedding_dim = vec.shape[0]
                    vec /= (np.linalg.norm(vec) + 1e-8)
                    neg_list.append(vec)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å negative {i}: {e}")
        
        if embedding_dim is None:
            # –ü—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –ø–æ–∑–∏—Ç–∏–≤–æ–≤, –µ—Å–ª–∏ –Ω–µ–≥–∞—Ç–∏–≤–æ–≤ –Ω–µ –±—ã–ª–æ
            if pos_by_class:
                try:
                    cls, imgs = next(iter(pos_by_class.items()))
                    if imgs:
                        vec = self._get_image_embedding(imgs[0], model, layer, transform)
                        if vec is not None:
                            embedding_dim = vec.reshape(-1).shape[0]
                except Exception:
                    pass
            if embedding_dim is None:
                embedding_dim = 1024 # Fallback

        q_neg = np.stack(neg_list, axis=0) if neg_list else np.zeros((0, embedding_dim), dtype=np.float32)

        # –¢–µ–ø–µ—Ä—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –ø–æ –∫–ª–∞—Å—Å–∞–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¶–ï–ù–¢–†–ê–õ–¨–ù–´–ï –û–ë–õ–ê–°–¢–ò –≤–º–µ—Å—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        class_pos = {}
        for cls, imgs in (pos_by_class or {}).items():
            pos_list = []
            for i, img in enumerate(imgs or []):
                try:
                    # –î–ª—è positive –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –æ–±—ä–µ–∫—Ç –≤ —Ü–µ–Ω—Ç—Ä–µ)
                    pos_regions = self._extract_central_region_from_image(img)
                    for region_vec in pos_regions:
                        if region_vec is None:
                            continue
                        vec = np.asarray(region_vec, dtype=np.float32).reshape(-1)
                        vec /= (np.linalg.norm(vec) + 1e-8)
                        pos_list.append(vec)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å positive '{cls}' #{i}: {e}")
            
            Q = np.stack(pos_list, axis=0) if pos_list else np.zeros((0, embedding_dim), dtype=np.float32)
            class_pos[cls] = Q.astype(np.float32)
            print(f"   üìä –ö–ª–∞—Å—Å '{cls}': {Q.shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤")

        print(f"   üìä Negative –≤—Å–µ–≥–æ: {q_neg.shape[0]}")
        return class_pos, q_neg

    def _extract_random_regions_from_image(self, pil_image, num_regions=5):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –º–∞—Å–∫–∞–º–∏."""
        import random
        import numpy as np
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ numpy
        image_np = np.array(pil_image)
        h, w = image_np.shape[:2]
        
        # –†–∞–∑–º–µ—Ä —Å–ª—É—á–∞–π–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä–Ω–æ –∫–∞–∫ —Å—Ä–µ–¥–Ω—è—è –º–∞—Å–∫–∞)
        region_size = min(h, w) // 4  # –ß–µ—Ç–≤–µ—Ä—Ç—å –æ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        region_size = max(32, region_size)  # –ú–∏–Ω–∏–º—É–º 32 –ø–∏–∫—Å–µ–ª—è
        
        regions = []
        for _ in range(num_regions):
            # –°–ª—É—á–∞–π–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –æ–±–ª–∞—Å—Ç–∏
            x = random.randint(0, max(0, w - region_size))
            y = random.randint(0, max(0, h - region_size))
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏
            mask = np.zeros((h, w), dtype=bool)
            mask[y:y+region_size, x:x+region_size] = True
            
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏ –∫–∞–∫ –¥–ª—è –æ–±—ã—á–Ω–æ–π –º–∞—Å–∫–∏
                if self.backbone.startswith('dinov3'):
                    region_emb = self._extract_with_dinov3_convnext(image_np, [mask])
                elif self.backbone.startswith('dinov2'):
                    region_emb = self._extract_with_dino(image_np, [mask])
                else:
                    # –î–ª—è ResNet –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ —Å –º–∞—Å–∫–æ–π
                    region_emb = self._extract_slow(pil_image, [mask])
                
                if region_emb is not None and len(region_emb) > 0:
                    regions.append(region_emb[0])  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) —ç–º–±–µ–¥–¥–∏–Ω–≥
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–∞: {e}")
                continue
        
        return regions

    def _extract_central_region_from_image(self, pil_image):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è positive –ø—Ä–∏–º–µ—Ä–æ–≤."""
        import numpy as np
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ numpy
        image_np = np.array(pil_image)
        h, w = image_np.shape[:2]
        
        # –†–∞–∑–º–µ—Ä —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ (60% –æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        region_h = int(h * 0.6)
        region_w = int(w * 0.6)
        
        # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –æ–±–ª–∞—Å—Ç—å
        start_y = (h - region_h) // 2
        start_x = (w - region_w) // 2
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
        mask = np.zeros((h, w), dtype=bool)
        mask[start_y:start_y+region_h, start_x:start_x+region_w] = True
        
        regions = []
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
            if self.backbone.startswith('dinov3'):
                region_emb = self._extract_with_dinov3_convnext(image_np, [mask])
            elif self.backbone.startswith('dinov2'):
                region_emb = self._extract_with_dino(image_np, [mask])
            else:
                # –î–ª—è ResNet –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ —Å –º–∞—Å–∫–æ–π
                region_emb = self._extract_slow(pil_image, [mask])
            
            if region_emb is not None and len(region_emb) > 0:
                regions.append(region_emb[0])  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) —ç–º–±–µ–¥–¥–∏–Ω–≥
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: {e}")
            # Fallback –∫ –≥–ª–æ–±–∞–ª—å–Ω–æ–º—É —ç–º–±–µ–¥–¥–∏–Ω–≥—É –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å
            try:
                resnet, layer, transform, sam = (
                    self.detector.searchdet_resnet,
                    self.detector.searchdet_layer,
                    self.detector.searchdet_transform,
                    self.detector.searchdet_sam
                )
                if isinstance(resnet, tuple) and len(resnet) >= 2:
                    model = resnet[0]
                else:
                    model = resnet
                
                vec = self._get_image_embedding(pil_image, model, layer, transform)
                if vec is not None:
                    regions.append(vec)
            except Exception:
                pass
        
        return regions


    # =========================
    # DINOv3 ConvNeXt-B support
    # =========================
    def _ensure_dinov3_convnext(self):
        import os, torch, timm
        from torchvision import transforms as T
        from torchvision.transforms import InterpolationMode

        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –µ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–º), —É–±–µ–¥–∏–º—Å—è —á—Ç–æ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω device –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
        if self._dinov3_model is not None:
            if self._dinov3_device is None:
                try:
                    self._dinov3_device = next(self._dinov3_model.parameters()).device
                except StopIteration:
                    self._dinov3_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            if self._dinov3_preprocess is None:
                img_size = int(os.getenv('SEARCHDET_FEAT_SHORT_SIDE', '224'))
                self._dinov3_preprocess = T.Compose([
                    T.Resize((img_size, img_size), interpolation=InterpolationMode.BICUBIC),
                    T.ToTensor(),
                    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
                ])
            return

        if not self.dinov3_ckpt:
            raise FileNotFoundError("–£–∫–∞–∂–∏ --dinov3-ckpt –ø—É—Ç—å –∫ .pth")

        # ConvNeXt-B –±–µ–∑ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ -> model(x) –¥–∞—ë—Ç pooled features
        self._dinov3_model = timm.create_model('convnext_base', pretrained=False, num_classes=0)
        sd = torch.load(self.dinov3_ckpt, map_location='cpu')
        if isinstance(sd, dict) and 'model' in sd: sd = sd['model']
        self._dinov3_model.load_state_dict(sd, strict=False)
        self._dinov3_model.eval()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å
        self._dinov3_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self._dinov3_model.to(self._dinov3_device)

        img_size = int(os.getenv('SEARCHDET_FEAT_SHORT_SIDE', '224'))
        self._dinov3_preprocess = T.Compose([
            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.BICUBIC),
            T.ToTensor(),
            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
        ])

    def _get_dinov3_global(self, image_np):
        import torch
        from PIL import Image as PILImage
        self._ensure_dinov3_convnext()
        x = self._dinov3_preprocess(PILImage.fromarray(image_np)).unsqueeze(0).to(self._dinov3_device)
        with torch.no_grad():
            feats = self._dinov3_model.forward_features(x)
            if isinstance(feats, dict):
                feats = feats.get('x', None) or feats.get('features', None)
            if feats.ndim == 3:
                feats = feats.unsqueeze(0)
            assert feats.ndim == 4, "–û–∂–∏–¥–∞–ª–∏ [B,C,Hf,Wf] –æ—Ç forward_features"
            fmap = feats[0].detach().cpu().float().numpy().transpose(1, 2, 0)  # (Hf, Wf, C)
            v = fmap.reshape(-1, fmap.shape[-1]).mean(axis=0).astype(np.float32)  # spatial mean
        v /= (np.linalg.norm(v) + 1e-8)
        if v.shape[0] != 1024:
            out = np.zeros(1024, dtype=np.float32)
            out[:min(1024, v.shape[0])] = v[:min(1024, v.shape[0])]
            v = out
        return v.astype(np.float32)


    def _extract_with_dinov3_convnext(self, image_np, mask_arrays):
        import torch, cv2, numpy as np
        from PIL import Image as PILImage

        self._ensure_dinov3_convnext()
        if self._dinov3_model is None:
            return np.zeros((0, 1024), dtype=np.float32)

        # 1) –û–¥–∏–Ω –ø—Ä–æ–≥–æ–Ω –ø–æ–ª–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è -> spatial feature map
        x_full = self._dinov3_preprocess(PILImage.fromarray(image_np)).unsqueeze(0).to(self._dinov3_device)
        with torch.no_grad():
            feats = self._dinov3_model.forward_features(x_full)
            # feats: [1, C, Hf, Wf] –¥–ª—è ConvNeXt; –∏–Ω–æ–≥–¥–∞ timm –≤–µ—Ä–Ω—ë—Ç dict -> –ø—Ä–∏–≤–µ–¥–∏ –∫ —Ç–µ–Ω–∑–æ—Ä—É
            if isinstance(feats, dict):
                # timm convnext –æ–±—ã—á–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä; –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π:
                feats = feats.get('x', None) or feats.get('features', None)
            if feats.ndim == 3:  # [C,Hf,Wf]
                feats = feats.unsqueeze(0)
            assert feats.ndim == 4, "–û–∂–∏–¥–∞–ª–∏ [B,C,Hf,Wf] –æ—Ç forward_features"

        feats_cpu = feats.detach().cpu()
        B, C, Hf, Wf = feats_cpu.shape
        fmap = feats_cpu[0].float().numpy().transpose(1,2,0)  # (Hf,Wf,C)

        embs = []
        for mask in mask_arrays:
            # 2) –ú–∞—Å–∫—É —Ä–µ—Å–∞–π–∑–∏–º –∫ —Ä–∞–∑–º–µ—Ä—É —Ñ–∏—á-–∫–∞—Ä—Ç—ã –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º –¢–û–õ–¨–ö–û –ø–æ –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ–∑–∏—Ü–∏—è–º
            m = cv2.resize(mask.astype(np.uint8), (Wf, Hf), interpolation=cv2.INTER_NEAREST).astype(bool)
            if not m.any():
                # –ú–∞—Å–∫–∞ –ø—É—Å—Ç–∞ –ø–æ—Å–ª–µ —Ä–µ—Å–∞–π–∑–∞. –ù–∞–π–¥–µ–º —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å –∏—Å—Ö–æ–¥–Ω–æ–π –º–∞—Å–∫–∏
                # –∏ –≤–æ–∑—å–º–µ–º –≤–µ–∫—Ç–æ—Ä –∏–∑ —ç—Ç–æ–π —Ç–æ—á–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
                if np.any(mask):
                    moments = cv2.moments(mask.astype(np.uint8))
                    if moments["m00"] > 0:
                        orig_x = int(moments["m10"] / moments["m00"])
                        orig_y = int(moments["m01"] / moments["m00"])
                    else:
                        # Fallback for very weird masks where moments are zero.
                        orig_y_arr, orig_x_arr = np.where(mask)
                        orig_y, orig_x = int(np.mean(orig_y_arr)), int(np.mean(orig_x_arr))

                    fy = int(orig_y / mask.shape[0] * Hf)
                    fx = int(orig_x / mask.shape[1] * Wf)
                    fy = np.clip(fy, 0, Hf - 1)
                    fx = np.clip(fx, 0, Wf - 1)
                    v = fmap[fy, fx].copy().astype(np.float32)
                else:
                    # –ï—Å–ª–∏ –∏ –∏—Å—Ö–æ–¥–Ω–∞—è –º–∞—Å–∫–∞ –ø—É—Å—Ç–∞, —Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                    v = fmap.reshape(-1, C).mean(axis=0).astype(np.float32)
            else:
                v = fmap[m].mean(axis=0).astype(np.float32)
            # 3) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è L2
            v /= (np.linalg.norm(v) + 1e-8)
            # ConvNeXt-B -> 1024-D
            if v.shape[0] != 1024:
                out = np.zeros(1024, dtype=np.float32)
                out[:min(1024, v.shape[0])] = v[:min(1024, v.shape[0])]
                v = out
            embs.append(v)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –ø—Ä–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        if embs:
            embs_array = np.stack(embs, axis=0)
            print("DEBUG mask_emb std:", np.std(embs_array, axis=0)[:8], "||", np.std(embs_array))
            return embs_array
        return np.zeros((0,1024), dtype=np.float32)
