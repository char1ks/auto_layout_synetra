# embeddings.py

import os
import glob
import numpy as np
from PIL import Image
import cv2
import torch

from .dinov3_encoder import DinoV3Encoder


def _iter_images(root):
    exts = ("*.jpg", "*.jpeg", "*.png", "*.bmp", "*.webp", "*.tif", "*.tiff")
    paths = []
    for e in exts:
        paths.extend(glob.glob(os.path.join(root, e)))
    return sorted(paths)

def extract_features_from_masks(encoder, masked_crops):
    """
    masked_crops: List[PIL.Image] ‚Äî –≤—ã—Ä–µ–∑–∫–∏ –ø–æ–¥ –º–∞—Å–∫–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: np.ndarray (N,D)
    """
    feats = []
    # –ü–æ–ª—É—á–∞–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π dtype/device –∏–∑ –º–æ–¥–µ–ª–∏
    p = next(encoder.model.parameters())
    dev, dt = p.device, p.dtype

    for im in masked_crops:
        x = encoder.tf(im).unsqueeze(0)                  # cpu float32
        x = x.to(device=dev, dtype=dt, non_blocking=True)
        with torch.no_grad():
            f = encoder.model.forward_features(x)
            # —Ç–æ—Ç –∂–µ —Å–ø–æ—Å–æ–±, —á—Ç–æ –∏ –≤ encoder.encode
            if hasattr(encoder.model, "forward_head"):
                out = encoder.model.forward_head(f, pre_logits=True)
            else:
                out = f
            if out.ndim == 2:
                v = out[0]
            elif out.ndim == 3:
                if encoder.pooling == "mean" and out.shape[1] > 1:
                    v = out[0, 1:].mean(dim=0)
                else:
                    v = out[0, 0]
            elif out.ndim == 4:
                v = out.mean(dim=(2, 3))[0]
            else:
                v = out.flatten(1)[0]
            v = torch.nn.functional.normalize(v.float(), dim=0)
            feats.append(v.cpu().numpy().astype(np.float32))

    if not feats:
        return np.zeros((0, 1), dtype=np.float32)
    return np.stack(feats, axis=0)  # (N,D)


class EmbeddingExtractor:
    def __init__(self, detector):
        self.detector = detector
        self.encoder = DinoV3Encoder(device=detector.device)

    # ---------- –ù–ê–î–Å–ñ–ù–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï ROI –ú–ê–°–ö–ò –ß–ï–†–ï–ó DINOv3 ----------
    def _encode_mask_roi_with_dinov3(self, image_np: np.ndarray, mask_bool: np.ndarray) -> np.ndarray:
        """
        1) –±–µ—Ä—ë–º bbox –º–∞—Å–∫–∏,
        2) –≤—ã—Ä–µ–∑–∞–µ–º crop,
        3) –∑–∞–Ω—É–ª—è–µ–º —Ñ–æ–Ω (–ø–æ –º–∞—Å–∫–µ),
        4) –ø–æ–¥–∞—ë–º –≤ DINOv3-—ç–Ω–∫–æ–¥–µ—Ä,
        5) –≤–æ–∑–≤—Ä–∞—â–∞–µ–º L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä (float32).
        """
        if self.encoder is None:
            # safety: –ø—É—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä (–Ω–æ –ª—É—á—à–µ –≤—Å–µ–≥–¥–∞ –∏–º–µ—Ç—å —ç–Ω–∫–æ–¥–µ—Ä)
            return np.zeros(1024, dtype=np.float32)

        ys, xs = np.where(mask_bool)
        if ys.size == 0 or xs.size == 0:
            return np.zeros(self.encoder.model.embed_dim, dtype=np.float32)  # fallback

        y1, y2 = int(ys.min()), int(ys.max())
        x1, x2 = int(xs.min()), int(xs.max())

        crop = image_np[y1:y2+1, x1:x2+1].copy()
        m    = mask_bool[y1:y2+1, x1:x2+1]
        # –∑–∞–Ω—É–ª—è–µ–º —Ñ–æ–Ω
        if m.dtype != bool:
            m = m.astype(bool)
        crop[~m] = 0

        pil = Image.fromarray(crop)
        vec = self.encoder.encode(pil)  # —É–∂–µ float32 + L2 norm –≤–Ω—É—Ç—Ä–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞
        return vec

    # ---------- –ú–ê–°–ö–ò: –í–°–ï–ì–î–ê –ß–ï–†–ï–ó DINOv3 ----------
    def extract_mask_embeddings(self, image_np, masks):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          - np.ndarray (N, D) float32, L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫,
          - —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫ (–∫–∞–∫ —Ä–∞–Ω—å—à–µ).
        """
        print("üß† –≠–¢–ê–ü 2: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤...")
        if not isinstance(masks, (list, tuple)) or len(masks) == 0:
            print("   ‚ùå –ù–µ—Ç –º–∞—Å–æ–∫ –Ω–∞ –≤—Ö–æ–¥–µ")
            return np.zeros((0, 1024), dtype=np.float32), []

        if self.encoder is None:
            print("   ‚ùå DINOv3-—ç–Ω–∫–æ–¥–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ detector")
            return np.zeros((0, 1024), dtype=np.float32), []

        vecs = []
        valid_ids = []
        for i, md in enumerate(masks):
            m = md.get("segmentation", None)
            if m is None or not isinstance(m, np.ndarray):
                continue
            try:
                v = self._encode_mask_roi_with_dinov3(image_np, m.astype(bool))
                if v is not None and v.size > 0:
                    vecs.append(v.astype(np.float32, copy=False))
                    valid_ids.append(i)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –ú–∞—Å–∫–∞ {i}: –æ—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ DINOv3: {e}")

        if not vecs:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—Å–æ–∫.")
            return np.zeros((0, 1024), dtype=np.float32), []

        X = np.stack(vecs, axis=0).astype(np.float32, copy=False)
        # sanity: –≤–µ–∫—Ç–æ—Ä—ã —É–∂–µ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –≤ —ç–Ω–∫–æ–¥–µ—Ä–µ
        print(f"   üìä –ú–∞—Å–æ–∫ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏: {X.shape[0]}")
        return X, valid_ids

    # ---------- –ü–†–ò–ú–ï–†–´: –í–°–ï–ì–î–ê –ß–ï–†–ï–ó DINOv3 ----------
    def build_queries_multiclass(self, pos_input: dict | str,
                              negative_dir: str | None,
                              pos_as_query_masks: bool,
                              mask_crops_by_class: dict[str, list] | None = None,
                              max_per_class: int = 64) -> tuple[dict[str, np.ndarray], np.ndarray]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          q_pos: dict[class_name] -> (K_i, D) ‚Äî –ù–û–†–ú–ò–†–û–í–ê–ù–ù–´–ï –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–º–µ—Ä–æ–≤
          q_neg: (K_neg, D) –∏–ª–∏ shape (0, D), –µ—Å–ª–∏ –Ω–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–æ–≤

        –ï—Å–ª–∏ negative_dir –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–ø—É—Å—Ç, –±—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω –æ–Ω–ª–∞–π–Ω-–Ω–µ–≥–∞—Ç–∏–≤ –∏–∑ —Ñ–æ–Ω–æ–≤—ã—Ö –º–∞—Å–æ–∫
        (–ø–µ—Ä–µ–¥–∞–π –µ–≥–æ –ø–æ–∑–∂–µ –≤ score_multiclass —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä `online_negatives`).
        """
        q_pos: dict[str, np.ndarray] = {}
        q_neg_list: list[np.ndarray] = []

        if self.encoder is None:
            print("   ‚ùå DINOv3-—ç–Ω–∫–æ–¥–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ detector")
            # –ø—É—Å—Ç—ã–µ, —á—Ç–æ–±—ã —Å–∫–æ—Ä–∏–Ω–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª
            return {}, np.zeros((0, 1024), dtype=np.float32)

        # POS: –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ dict {class:[paths]} –∏–ª–∏ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–æ–¥–ø–∞–ø–∫–∞–º–∏-–∫–ª–∞—Å—Å–∞–º–∏
        pos_class_iterator = None
        is_dir_mode = False
        if isinstance(pos_input, str) and os.path.isdir(pos_input):
            pos_class_iterator = sorted(os.listdir(pos_input))
            is_dir_mode = True
        elif isinstance(pos_input, dict):
            pos_class_iterator = sorted(pos_input.keys())
            is_dir_mode = False

        if pos_class_iterator:
            for cls in pos_class_iterator:
                image_paths = []
                if is_dir_mode:
                    cls_dir = os.path.join(pos_input, cls)
                    if not os.path.isdir(cls_dir):
                        continue
                    image_paths = _iter_images(cls_dir)
                else: # dict
                    image_paths = pos_input[cls]

                vecs: list[np.ndarray] = []
                if pos_as_query_masks and mask_crops_by_class and cls in mask_crops_by_class:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞—Å–∫–∏ –∏–∑ positive –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∑–∞–ø—Ä–æ—Å–æ–≤
                    for im in mask_crops_by_class[cls][:max_per_class]:
                        vecs.append(self.encoder.encode(im))
                else:
                    # –ë–µ—Ä—ë–º —Ü–µ–ª—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–ª–∞—Å—Å–∞
                    for item in image_paths[:max_per_class]:
                        try:
                            if isinstance(item, Image.Image):
                                im = item.convert("RGB")
                            else:
                                im = Image.open(item).convert("RGB")
                            vecs.append(self.encoder.encode(im))
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ positive-–ø—Ä–∏–º–µ—Ä–∞ {item}: {e}")
                            continue

                if vecs:
                    arr = np.stack(vecs, 0)
                    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –µ–¥–∏–Ω–∏—á–Ω—ã–º (–Ω–∞ –≤—Å—è–∫–∏–π)
                    arr = arr / (np.linalg.norm(arr, axis=1, keepdims=True) + 1e-8)
                    q_pos[cls] = arr

        # NEG: —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤—ã
        if negative_dir and os.path.isdir(negative_dir):
            for p in _iter_images(negative_dir)[:256]:
                try:
                    im = Image.open(p).convert("RGB")
                    v = self.encoder.encode(im)
                    q_neg_list.append(v / (np.linalg.norm(v) + 1e-8))
                except Exception:
                    continue

        q_neg = np.stack(q_neg_list, 0) if q_neg_list else np.zeros((0, 1), dtype=np.float32)
        return q_pos, q_neg
